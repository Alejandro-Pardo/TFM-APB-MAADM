{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a788cf",
   "metadata": {},
   "source": [
    "# AWS Services Embeddings Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6df43407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "from embedding_checkpoint import EmbeddingCheckpointManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35977ec-4b09-4de6-98e2-5211a183baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking CUDA availability...\n",
      "PyTorch version: 2.4.0a0+f70bd71a48.nv24.06\n",
      "CUDA available: True\n",
      "CUDA version: 12.5\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA RTX 6000 Ada Generation (47.5 GB)\n",
      "Current device: 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability and GPU information\n",
    "print(\"ðŸ” Checking CUDA availability...\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "        print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"âŒ CUDA not available - will use CPU\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e9f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSEmbeddingCreator:\n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen3-Embedding-4B\", batch_size: int = 32, \n",
    "                 checkpoint_file: str = \"embeddings/embeddings_checkpoint.json\"):\n",
    "        \"\"\"Initialize the embedding creator with the specified model.\"\"\"\n",
    "        self.model = SentenceTransformer(\n",
    "            model_name,\n",
    "            model_kwargs={\n",
    "                \"attn_implementation\": \"flash_attention_2\",\n",
    "                \"device_map\": \"auto\",\n",
    "                \"torch_dtype\": torch.bfloat16  # optimal for RTX 6000 Ada\n",
    "            },\n",
    "            tokenizer_kwargs={\"padding_side\": \"left\"}\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoint_manager = EmbeddingCheckpointManager(checkpoint_file)\n",
    "        \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize text for embedding.\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        # Remove excessive whitespace and newlines\n",
    "        text = \" \".join(text.split())\n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_parameter_description(self, description: str) -> str:\n",
    "        \"\"\"Clean parameter descriptions by removing type annotations and extra formatting.\"\"\"\n",
    "        if not description:\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove patterns like \"(string) ---\", \"(dict) ---\", \"(integer) ---\", etc.\n",
    "        # This regex matches: opening paren, word characters, closing paren, optional spaces, three dashes\n",
    "        description = re.sub(r'\\([a-zA-Z]+\\)\\s*---\\s*', '', description)\n",
    "        \n",
    "        # Clean up any remaining multiple spaces\n",
    "        description = re.sub(r'\\s+', ' ', description)\n",
    "        \n",
    "        return description.strip()\n",
    "    \n",
    "    def convert_case_to_words(self, name: str) -> str:\n",
    "        \"\"\"Convert PascalCase, camelCase, or snake_case to words.\"\"\"\n",
    "        if not name:\n",
    "            return \"\"\n",
    "        \n",
    "        # Handle snake_case\n",
    "        name = name.replace(\"_\", \" \")\n",
    "        \n",
    "        # Handle PascalCase and camelCase\n",
    "        # Add space before uppercase letters that follow lowercase letters\n",
    "        result = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', name)\n",
    "        # Add space before uppercase letters that are followed by lowercase letters\n",
    "        result = re.sub(r'([A-Z]+)([A-Z][a-z])', r'\\1 \\2', result)\n",
    "        \n",
    "        return result.strip()\n",
    "    \n",
    "    def convert_names_in_description(self, description: str) -> str:\n",
    "        \"\"\"Convert PascalCase/camelCase names in description to space-separated words.\"\"\"\n",
    "        if not description:\n",
    "            return \"\"\n",
    "        \n",
    "        # Find words that are likely PascalCase/camelCase (start with capital, contain mixed case)\n",
    "        # This regex finds words that start with a capital and have at least one lowercase followed by uppercase\n",
    "        pattern = r'\\b[A-Z][a-z]*[A-Z][a-zA-Z]*\\b'\n",
    "        \n",
    "        def replace_case(match):\n",
    "            return self.convert_case_to_words(match.group())\n",
    "        \n",
    "        # Replace PascalCase/camelCase words with space-separated versions\n",
    "        result = re.sub(pattern, replace_case, description)\n",
    "        \n",
    "        return result.strip()\n",
    "    \n",
    "    def format_parameters(self, parameters: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format parameters into a string representation.\"\"\"\n",
    "        if not parameters:\n",
    "            return \"\"\n",
    "        \n",
    "        param_strs = []\n",
    "        for param in parameters:\n",
    "            param_name = self.convert_case_to_words(param.get('name', ''))\n",
    "            param_desc = self.clean_text(param.get('description', ''))\n",
    "            # Convert case in parameter description too\n",
    "            param_desc = self.convert_names_in_description(param_desc)\n",
    "            # Clean parameter description\n",
    "            param_desc = self.clean_parameter_description(param_desc)\n",
    "            \n",
    "            if param_name and param_desc:\n",
    "                param_str = f\"{param_name}: {param_desc}\"\n",
    "            elif param_name:\n",
    "                param_str = param_name\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            param_strs.append(param_str)\n",
    "        \n",
    "        return \"Parameters: \" + \" | \".join(param_strs) if param_strs else \"\"\n",
    "    \n",
    "    def format_return_structure(self, return_structure: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format return structure into a string representation.\"\"\"\n",
    "        if not return_structure:\n",
    "            return \"\"\n",
    "        \n",
    "        return_strs = []\n",
    "        for item in return_structure:\n",
    "            nested_items = item.get('nested_items', [])\n",
    "            if nested_items:\n",
    "                for nested in nested_items:\n",
    "                    field_name = self.convert_case_to_words(nested.get('name', ''))\n",
    "                    field_desc = self.clean_text(nested.get('description', ''))\n",
    "                    # Convert case in field description too\n",
    "                    field_desc = self.convert_names_in_description(field_desc)\n",
    "                    # Clean field description\n",
    "                    field_desc = self.clean_parameter_description(field_desc)\n",
    "                    \n",
    "                    if field_name and field_desc:\n",
    "                        return_str = f\"{field_name}: {field_desc}\"\n",
    "                    elif field_name:\n",
    "                        return_str = field_name\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    return_strs.append(return_str)\n",
    "        \n",
    "        return \"Returns: \" + \" | \".join(return_strs) if return_strs else \"\"\n",
    "    \n",
    "    def create_service_format(self, service_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"Create the single format representation for a service.\"\"\"\n",
    "        name = service_data['service_name']\n",
    "        description = self.clean_text(service_data['client'].get('description', ''))\n",
    "        \n",
    "        # Convert PascalCase/camelCase names in description to words\n",
    "        description = self.convert_names_in_description(description)\n",
    "        \n",
    "        # Convert name to words\n",
    "        name_words = self.convert_case_to_words(name)\n",
    "        \n",
    "        # Combine name and description\n",
    "        if description:\n",
    "            return f\"{name_words}. {description}\"\n",
    "        else:\n",
    "            return name_words\n",
    "    \n",
    "    def create_method_formats(self, method_data: Dict[str, Any], \n",
    "                            service_name: str, service_description: str) -> Dict[str, str]:\n",
    "        \"\"\"Create the three format representations for a method.\"\"\"\n",
    "        method_name = method_data.get('method_name', '')\n",
    "        method_description = self.clean_text(method_data.get('description', ''))\n",
    "        \n",
    "        # Convert PascalCase/camelCase names in description to words\n",
    "        method_description = self.convert_names_in_description(method_description)\n",
    "        \n",
    "        # Convert names to words\n",
    "        method_name_words = self.convert_case_to_words(method_name)\n",
    "        service_name_words = self.convert_case_to_words(service_name)\n",
    "        \n",
    "        # Format parameters and returns\n",
    "        params = self.format_parameters(method_data.get('parameters', []))\n",
    "        returns = self.format_return_structure(method_data.get('return_structure', []))\n",
    "        \n",
    "        formats = {}\n",
    "        \n",
    "        # Format 1: method name + description\n",
    "        if method_description:\n",
    "            formats['method_only'] = f\"{method_name_words}. {method_description}\"\n",
    "        else:\n",
    "            formats['method_only'] = method_name_words\n",
    "        \n",
    "        # Format 2: method + parameters\n",
    "        parts = []\n",
    "        if method_description:\n",
    "            parts.append(f\"{method_name_words}. {method_description}\")\n",
    "        else:\n",
    "            parts.append(method_name_words)\n",
    "            \n",
    "        if params:\n",
    "            parts.append(params)\n",
    "            \n",
    "        formats['with_params'] = \" \".join(parts)\n",
    "        \n",
    "        # Format 3: service + method + parameters + returns\n",
    "        if returns:\n",
    "            formats['with_params_returns'] = formats['with_params'] + \" \" + returns\n",
    "        else:\n",
    "            formats['with_params_returns'] = formats['with_params']\n",
    "        \n",
    "        return formats\n",
    "    \n",
    "    def create_embeddings_batch(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Create embeddings for a batch of texts.\"\"\"\n",
    "        # Filter out empty texts\n",
    "        texts = [t for t in texts if t and t.strip()]\n",
    "        if not texts:\n",
    "            return np.array([])\n",
    "        \n",
    "        embeddings = self.model.encode(texts, batch_size=self.batch_size, show_progress_bar=False)\n",
    "        return embeddings\n",
    "    \n",
    "    def save_service_embedding(self, service_name: str, embedding: np.ndarray, \n",
    "                              formatted_text: str, output_dir: Path):\n",
    "        \"\"\"Save individual service embedding to file.\"\"\"\n",
    "        service_file = output_dir / \"services\" / f\"{service_name}.json\"\n",
    "        service_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        data = {\n",
    "            \"service_name\": service_name,\n",
    "            \"formatted_text\": formatted_text,\n",
    "            \"embedding\": embedding.tolist()\n",
    "        }\n",
    "        \n",
    "        with open(service_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    def save_method_embedding(self, service_name: str, method_name: str, \n",
    "                            formats: Dict[str, str], embeddings: Dict[str, np.ndarray], \n",
    "                            output_dir: Path):\n",
    "        \"\"\"Save individual method embedding to file.\"\"\"\n",
    "        method_file = output_dir / \"methods\" / service_name / f\"{method_name}.json\"\n",
    "        method_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        data = {\n",
    "            \"service_name\": service_name,\n",
    "            \"method_name\": method_name,\n",
    "            \"formats\": formats,\n",
    "            \"embeddings\": {k: v.tolist() for k, v in embeddings.items()}\n",
    "        }\n",
    "        \n",
    "        with open(method_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    def process_services(self, services_dir: Path, output_dir: Path) -> Dict[str, str]:\n",
    "        \"\"\"Process all service files and create embeddings with checkpoint support.\"\"\"\n",
    "        self.checkpoint_manager.set_phase(\"services\")\n",
    "        \n",
    "        service_descriptions = {}  # Store for later use with methods\n",
    "        service_files = list(services_dir.glob(\"*.json\"))\n",
    "        \n",
    "        # Check resume info\n",
    "        resume_info = self.checkpoint_manager.get_resume_info()\n",
    "        print(f\"Resume info: {resume_info}\")\n",
    "        \n",
    "        # Filter out already processed services\n",
    "        services_to_process = []\n",
    "        for service_file in service_files:\n",
    "            service_name = service_file.stem\n",
    "            if not self.checkpoint_manager.is_service_processed(service_name):\n",
    "                services_to_process.append(service_file)\n",
    "            else:\n",
    "                # Still need to load description for methods processing\n",
    "                with open(service_file, 'r') as f:\n",
    "                    service_data = json.load(f)\n",
    "                    service_desc = self.clean_text(service_data['client'].get('description', ''))\n",
    "                    cleaned_desc = self.convert_names_in_description(service_desc)\n",
    "                    service_descriptions[service_name] = cleaned_desc\n",
    "        \n",
    "        if services_to_process:\n",
    "            print(f\"Processing {len(services_to_process)} remaining services (out of {len(service_files)} total)...\")\n",
    "            \n",
    "            for service_file in tqdm(services_to_process, desc=\"Processing services\"):\n",
    "                with open(service_file, 'r') as f:\n",
    "                    service_data = json.load(f)\n",
    "                    service_name = service_data['service_name']\n",
    "                    \n",
    "                    # Store clean description for methods\n",
    "                    service_desc = self.clean_text(service_data['client'].get('description', ''))\n",
    "                    cleaned_desc = self.convert_names_in_description(service_desc)\n",
    "                    service_descriptions[service_name] = cleaned_desc\n",
    "                    \n",
    "                    # Create format\n",
    "                    formatted_text = self.create_service_format(service_data)\n",
    "                    \n",
    "                    # Create embedding\n",
    "                    embedding = self.create_embeddings_batch([formatted_text])[0]\n",
    "                    \n",
    "                    # Save individual service embedding\n",
    "                    self.save_service_embedding(service_name, embedding, formatted_text, output_dir)\n",
    "                    \n",
    "                    # Mark as processed\n",
    "                    self.checkpoint_manager.mark_service_as_processed(service_name)\n",
    "        else:\n",
    "            print(\"All services already processed!\")\n",
    "        \n",
    "        return service_descriptions\n",
    "    \n",
    "    def process_methods(self, methods_dir: Path, service_descriptions: Dict[str, str], \n",
    "                       output_dir: Path):\n",
    "        \"\"\"Process all method files and create embeddings with checkpoint support.\"\"\"\n",
    "        self.checkpoint_manager.set_phase(\"methods\")\n",
    "        \n",
    "        service_dirs = [d for d in methods_dir.iterdir() if d.is_dir()]\n",
    "        print(f\"\\nProcessing methods for {len(service_dirs)} services...\")\n",
    "        \n",
    "        for service_dir in tqdm(service_dirs, desc=\"Processing method services\"):\n",
    "            service_name = service_dir.name\n",
    "            service_desc = service_descriptions.get(service_name, \"\")\n",
    "            \n",
    "            method_files = list(service_dir.glob(\"*.json\"))\n",
    "            \n",
    "            # Filter out already processed methods\n",
    "            methods_to_process = []\n",
    "            for method_file in method_files:\n",
    "                method_name = method_file.stem\n",
    "                if not self.checkpoint_manager.is_method_processed(service_name, method_name):\n",
    "                    methods_to_process.append(method_file)\n",
    "            \n",
    "            if not methods_to_process:\n",
    "                continue  # Skip if all methods in this service are processed\n",
    "            \n",
    "            for method_file in tqdm(methods_to_process, desc=f\"Methods in {service_name}\", leave=False):\n",
    "                with open(method_file, 'r') as f:\n",
    "                    method_data = json.load(f)\n",
    "                    method_name = method_data.get('method_name', '')\n",
    "                    \n",
    "                    if not method_name:  # Skip if no method name\n",
    "                        continue\n",
    "                    \n",
    "                    # Create formats\n",
    "                    formats = self.create_method_formats(method_data, service_name, service_desc)\n",
    "                    \n",
    "                    # Create embeddings for each format\n",
    "                    method_embeddings = {}\n",
    "                    for format_name, format_text in formats.items():\n",
    "                        embedding = self.create_embeddings_batch([format_text])[0]\n",
    "                        method_embeddings[format_name] = embedding\n",
    "                    \n",
    "                    # Save individual method embedding\n",
    "                    self.save_method_embedding(service_name, method_name, formats, \n",
    "                                             method_embeddings, output_dir)\n",
    "                    \n",
    "                    # Mark as processed\n",
    "                    self.checkpoint_manager.mark_method_as_processed(service_name, method_name)\n",
    "    \n",
    "    def get_checkpoint_status(self):\n",
    "        \"\"\"Get current checkpoint status.\"\"\"\n",
    "        return self.checkpoint_manager.get_resume_info()\n",
    "    \n",
    "    def reset_checkpoint(self):\n",
    "        \"\"\"Reset checkpoint to start fresh.\"\"\"\n",
    "        self.checkpoint_manager.reset_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "203ac4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26c9a123de34aefab430cf6ddf935c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5abe81db62485b8f6bdf8b6d743df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376bbba002ac4952a1f7377057861c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070e307d281f4a369028cc2c49021785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df7a956437745baa00ad05afe45d884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dc970f68114bb2a401a1fb759b3d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2ed8de16e94447927e785d58c1fac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddf6eedfcc1419a88bd47ef30482d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc04826971a4251885d54e79563c4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e1105bcb6d4f3cbde39939ca2ccd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d466b99f573418081baf92c5ebc3b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4218536806c641f7b6fab51fd5d54b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f703bb93cb6433fa5ec5c2646029405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57e0befa37e4a1cb98e77f1f9aae90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Checkpoint Status:\n",
      "ðŸ“ Current phase: services\n",
      "âœ… Services processed: 0\n",
      "âœ… Methods processed: 0\n",
      "ðŸ’¾ Checkpoint file: ../../embeddings/embeddings_checkpoint.json\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "project_root = Path(\"../..\")\n",
    "docs_dir = project_root / \"docs_subset\"\n",
    "services_dir = docs_dir / \"services_subset\"\n",
    "methods_dir = docs_dir / \"methods_subset\"\n",
    "output_dir = project_root / \"embeddings\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create the embedding creator with the correct checkpoint path\n",
    "checkpoint_file = output_dir / \"embeddings_checkpoint.json\"\n",
    "creator = AWSEmbeddingCreator(batch_size=32, checkpoint_file=str(checkpoint_file))\n",
    "\n",
    "# Show checkpoint status\n",
    "checkpoint_status = creator.get_checkpoint_status()\n",
    "print(\"ðŸ”„ Checkpoint Status:\")\n",
    "print(f\"ðŸ“ Current phase: {checkpoint_status['phase']}\")\n",
    "print(f\"âœ… Services processed: {checkpoint_status['services_processed']}\")\n",
    "print(f\"âœ… Methods processed: {checkpoint_status['methods_processed']}\")\n",
    "print(f\"ðŸ’¾ Checkpoint file: {checkpoint_file}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c7a5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Checkpoint reset! Starting fresh...\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below if you want to start fresh and reset the checkpoint\n",
    "# creator.reset_checkpoint()\n",
    "# print(\"ðŸ”„ Checkpoint reset! Starting fresh...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b424cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing services...\n",
      "Resume info: {'phase': 'services', 'services_processed': 0, 'methods_processed': 0}\n",
      "Processing 31 remaining services (out of 31 total)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b2a65e686a44fd8d0b68875574fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing services:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 31 services\n"
     ]
    }
   ],
   "source": [
    "# Process services\n",
    "print(\"Processing services...\")\n",
    "service_descriptions = creator.process_services(services_dir, output_dir)\n",
    "print(f\"Processed {len(service_descriptions)} services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8328849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing methods...\n",
      "\n",
      "Processing methods for 31 services...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d90e2a0f644dbfadc06e71d7513c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing method services:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66e966c11e94335b83da1454fc3437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SimpleDB:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2fb360f99d4a448a1e9f9f65ca3c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in CognitoIdentity:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59fd5c7456f4249a8b768d8d475e851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SES:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb6769a6026492cb19900722cb0fd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in STS:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f78ea5ab93046fdbffc24a0bb115837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Kinesis:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541513a686b84609bf98f4db5177fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SESV2:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95629b060e854157b0cb6f376779017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SSO:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b537c211414635b524ee13e3feaa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Lightsail:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62b044fa65d4d24b6b0c6e416ae0718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in ElastiCache:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a93e7720cc443c99889dd0f55dfd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Pinpoint:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4d0824735d4e4b88992ee0b040d956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Glacier:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b324655e524fb1afdefe571b383ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in S3:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62226c4405fe4504a2166b816a9a51d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SNS:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d908ab0020b4ebcae34a902877cfcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in EKS:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964e080e2af14e809d4fa3de6578d25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in ECS:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9714db83bfe84d23bb0617ec0aa25581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in EC2:   0%|          | 0/662 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787719a2bd95488aab5220c574d2ba5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in OpsWorks:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f380c4910c47369bbca9a18b7b513c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Lambda:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6623f12ed14b48aceb7883e6eee502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in AppRunner:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4b982ed2e2493eaee44ad5c971da71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in CloudFormation:   0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fdf20ff61048149b232ee84063bd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in DocDB:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed85998670544b79da4285a5a4c3d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SSM:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceeb780291e4566b75b423b1bd4e288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in SQS:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cf79fdd6054a2890fa670e56b3f6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in FSx:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3159d6e3ef14ed19ff778130a79fd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in DynamoDB:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6862c293044c78926d87c4738dac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in EventBridge:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41f7264178e4cefb8a0254dcf323c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in EBS:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ec128c38bc49d0b5905e98d3d720f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in RDS:   0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63467678a7d47ba9db9ca2792762418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in IAM:   0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6d17a95b45412d8d4c33a840ebde62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in EFS:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad81bc3318d845c5a476b04257ebb068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Methods in Neptune:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process methods\n",
    "print(\"\\nProcessing methods...\")\n",
    "creator.process_methods(methods_dir, service_descriptions, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dbecf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Embedding creation complete!\n",
      "ðŸ“‚ Created 31 service embedding files\n",
      "ðŸ“‚ Created 2766 method embedding files\n"
     ]
    }
   ],
   "source": [
    "# Count total files created\n",
    "service_files = len(list((output_dir / \"services\").glob(\"*.json\")))\n",
    "method_files = sum(\n",
    "    len(list(service_dir.glob(\"*.json\")))\n",
    "    for service_dir in (output_dir / \"methods\").iterdir()\n",
    "    if service_dir.is_dir()\n",
    ")\n",
    "\n",
    "# Final checkpoint status\n",
    "final_status = creator.get_checkpoint_status()\n",
    "\n",
    "print(f\"\\nâœ… Embedding creation complete!\")\n",
    "print(f\"ðŸ“‚ Created {service_files} service embedding files\")\n",
    "print(f\"ðŸ“‚ Created {method_files} method embedding files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1b19c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Final Checkpoint Status:\n",
      "ðŸ“ Phase: methods\n",
      "âœ… Services processed: 31\n",
      "âœ… Methods processed: 2766\n",
      "\n",
      "ðŸ’¾ Progress saved to embeddings_checkpoint.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ”„ Final Checkpoint Status:\")\n",
    "print(f\"ðŸ“ Phase: {final_status['phase']}\")\n",
    "print(f\"âœ… Services processed: {final_status['services_processed']}\")\n",
    "print(f\"âœ… Methods processed: {final_status['methods_processed']}\")\n",
    "print(\"\\nðŸ’¾ Progress saved to embeddings_checkpoint.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27a95fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata about formats\n",
    "metadata = {\n",
    "    \"service_format\": \"Service name (converted to words) + description (with PascalCase/camelCase converted)\",\n",
    "    \"method_formats\": {\n",
    "        \"method_only\": \"Method name + description\",\n",
    "        \"with_service_params\": \"Method name + method description + parameters\",\n",
    "        \"with_service_params_returns\": \"Method name + method description + parameters + returns\",\n",
    "    },\n",
    "    \"notes\": {\n",
    "        \"case_handling\": \"All PascalCase, camelCase, and snake_case names are converted to space-separated words\",\n",
    "        \"description_processing\": \"PascalCase/camelCase names within descriptions are converted to words\",\n",
    "        \"file_structure\": \"Each service and method gets its own JSON file with embedding and formatted text\",\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(output_dir / \"embedding_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
