{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2cc4d08-d484-4340-9b66-828e10bd5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from annoy import AnnoyIndex\n",
    "import pickle\n",
    "#import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import visualization utilities\n",
    "from visualization import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_threshold_analysis,\n",
    "    print_evaluation_summary,\n",
    "    print_service_predictions_summary,\n",
    "    create_results_dashboard,\n",
    "    save_visualization_summary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f5d6c4c-5591-4048-88b5-05047402d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWSLabelPropagator:\n",
    "    def __init__(self, embeddings_dir: Path, labels_file: Path, embedding_format: str = \"with_service_params\"):\n",
    "        \"\"\"\n",
    "        Initialize the label propagator.\n",
    "        \n",
    "        Args:\n",
    "            embeddings_dir: Path to directory containing embedding files\n",
    "            labels_file: Path to CSV file with manual labels\n",
    "            embedding_format: Which embedding format to use for propagation\n",
    "        \"\"\"\n",
    "        self.embeddings_dir = embeddings_dir\n",
    "        self.labels_file = labels_file\n",
    "        self.embedding_format = embedding_format\n",
    "        \n",
    "        # Load manual labels\n",
    "        self.manual_labels = self._load_manual_labels()\n",
    "        \n",
    "        # Storage for embeddings and labels\n",
    "        self.method_embeddings = {}\n",
    "        self.method_labels = {}\n",
    "        self.service_methods = defaultdict(list)\n",
    "        \n",
    "        # Annoy-specific storage\n",
    "        self.annoy_indexes = {}\n",
    "        self.method_lookups = {}\n",
    "        self.embedding_dim = None  # Will be auto-detected from first embedding\n",
    "        \n",
    "        print(f\"üè∑Ô∏è Loaded {len(self.manual_labels)} manual labels\")\n",
    "        print(f\"üìä Using embedding format: {embedding_format}\")\n",
    "    \n",
    "    def set_embedding_dimension(self, dimension: int) -> None:\n",
    "        \"\"\"\n",
    "        Set the embedding dimension manually.\n",
    "        \n",
    "        Args:\n",
    "            dimension: The embedding dimension to use\n",
    "        \"\"\"\n",
    "        self.embedding_dim = dimension\n",
    "        print(f\"üîß Embedding dimension set to: {dimension}\")\n",
    "    \n",
    "    def _validate_embedding_dimension(self) -> None:\n",
    "        \"\"\"Validate that embedding dimension is set.\"\"\"\n",
    "        if self.embedding_dim is None:\n",
    "            raise ValueError(\"Embedding dimension not set. Call set_embedding_dimension() or load embeddings first.\")\n",
    "    \n",
    "    def _load_manual_labels(self) -> Dict[Tuple[str, str], str]:\n",
    "        \"\"\"Load manual labels from CSV file.\"\"\"\n",
    "        df = pd.read_csv(self.labels_file, sep=';')\n",
    "        labels = {}\n",
    "        \n",
    "        current_service = None\n",
    "        for _, row in df.iterrows():\n",
    "            service = row['API Service'].strip() if pd.notna(row['API Service']) and row['API Service'].strip() else current_service\n",
    "            if service and service != current_service:\n",
    "                current_service = service\n",
    "            \n",
    "            method = row['Methods'].strip() if pd.notna(row['Methods']) else None\n",
    "            label = row['Sink/Source'].strip() if pd.notna(row['Sink/Source']) else None\n",
    "            \n",
    "            if method and label and current_service:\n",
    "                # Normalize labels\n",
    "                if label.lower() in ['source', 'source / x']:\n",
    "                    normalized_label = 'source'\n",
    "                elif label.lower() in ['sink']:\n",
    "                    normalized_label = 'sink'\n",
    "                else:\n",
    "                    normalized_label = 'none'\n",
    "                \n",
    "                labels[(current_service.lower(), method)] = normalized_label\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def load_method_embeddings(self, services: List[str] = None) -> None:\n",
    "        \"\"\"Load method embeddings for specified services.\"\"\"\n",
    "        methods_dir = self.embeddings_dir / \"methods\"\n",
    "        \n",
    "        if services is None:\n",
    "            services = [d.name for d in methods_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        print(f\"üìÇ Loading embeddings for services: {services}\")\n",
    "        \n",
    "        for service in services:\n",
    "            service_dir = methods_dir / service\n",
    "            if not service_dir.exists():\n",
    "                print(f\"‚ö†Ô∏è Service directory not found: {service}\")\n",
    "                continue\n",
    "            \n",
    "            method_files = list(service_dir.glob(\"*.json\"))\n",
    "            print(f\"üìÅ {service}: {len(method_files)} methods\")\n",
    "            \n",
    "            for method_file in method_files:\n",
    "                with open(method_file, 'r') as f:\n",
    "                    method_data = json.load(f)\n",
    "                    \n",
    "                    service_name = method_data['service_name'].lower()\n",
    "                    method_name = method_data['method_name']\n",
    "                    \n",
    "                    if self.embedding_format in method_data.get('embeddings', {}):\n",
    "                        embedding = np.array(method_data['embeddings'][self.embedding_format])\n",
    "                        \n",
    "                        # Auto-detect embedding dimension from first embedding\n",
    "                        if self.embedding_dim is None:\n",
    "                            self.embedding_dim = len(embedding)\n",
    "                            print(f\"üîç Auto-detected embedding dimension: {self.embedding_dim}\")\n",
    "                        \n",
    "                        # Validate dimension consistency\n",
    "                        if len(embedding) != self.embedding_dim:\n",
    "                            print(f\"‚ö†Ô∏è Warning: Embedding dimension mismatch for {service_name}.{method_name}: \"\n",
    "                                  f\"expected {self.embedding_dim}, got {len(embedding)}\")\n",
    "                            continue\n",
    "                        \n",
    "                        key = (service_name, method_name)\n",
    "                        \n",
    "                        self.method_embeddings[key] = embedding\n",
    "                        self.service_methods[service_name].append(method_name)\n",
    "                        \n",
    "                        # Add label if we have it manually labeled\n",
    "                        if key in self.manual_labels:\n",
    "                            self.method_labels[key] = self.manual_labels[key]\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(self.method_embeddings)} method embeddings\")\n",
    "        print(f\"üè∑Ô∏è Found {len(self.method_labels)} labeled methods\")\n",
    "        if self.embedding_dim:\n",
    "            print(f\"üìê Embedding dimension: {self.embedding_dim}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No embeddings loaded - dimension not detected\")\n",
    "    \n",
    "    def _build_service_index(self, service: str) -> None:\n",
    "        \"\"\"Build Annoy index for a specific service.\"\"\"\n",
    "        self._validate_embedding_dimension()\n",
    "        \n",
    "        service = service.lower()\n",
    "        service_methods = [(service, method) for method in self.service_methods[service]]\n",
    "        \n",
    "        # Create Annoy index\n",
    "        index = AnnoyIndex(self.embedding_dim, 'angular')  # angular = cosine distance\n",
    "        method_lookup = {}\n",
    "        \n",
    "        # Add embeddings to index\n",
    "        idx = 0\n",
    "        for method_key in service_methods:\n",
    "            if method_key in self.method_embeddings:\n",
    "                index.add_item(idx, self.method_embeddings[method_key])\n",
    "                method_lookup[idx] = method_key\n",
    "                idx += 1\n",
    "        \n",
    "        # Build index with 10 trees (good balance of speed/accuracy)\n",
    "        index.build(10)\n",
    "        \n",
    "        # Store index and lookup\n",
    "        self.annoy_indexes[service] = index\n",
    "        self.method_lookups[service] = method_lookup\n",
    "        \n",
    "        print(f\"   üîß Built Annoy index for {service}: {len(method_lookup)} methods\")\n",
    "    \n",
    "    def _ensure_service_index(self, service: str) -> None:\n",
    "        \"\"\"Ensure Annoy index exists for a service.\"\"\"\n",
    "        service = service.lower()\n",
    "        if service not in self.annoy_indexes:\n",
    "            self._build_service_index(service)\n",
    "    \n",
    "    def _get_neighbors_with_similarities(self, service: str, query_embedding: np.ndarray, k: int) -> List[Tuple[Tuple[str, str], float]]:\n",
    "        \"\"\"Get k nearest neighbors with cosine similarities.\"\"\"\n",
    "        self._ensure_service_index(service)\n",
    "        \n",
    "        index = self.annoy_indexes[service]\n",
    "        method_lookup = self.method_lookups[service]\n",
    "        \n",
    "        # Get more neighbors than needed since we'll filter\n",
    "        search_k = min(k * 3, len(method_lookup))\n",
    "        neighbor_indices = index.get_nns_by_vector(query_embedding, search_k)\n",
    "        \n",
    "        # Calculate actual cosine similarities\n",
    "        neighbors_with_sims = []\n",
    "        for idx in neighbor_indices:\n",
    "            if idx in method_lookup:\n",
    "                neighbor_key = method_lookup[idx]\n",
    "                neighbor_embedding = self.method_embeddings[neighbor_key]\n",
    "                \n",
    "                # Calculate cosine similarity (convert from distance)\n",
    "                similarity = cosine_similarity([query_embedding], [neighbor_embedding])[0][0]\n",
    "                neighbors_with_sims.append((neighbor_key, similarity))\n",
    "        \n",
    "        # Sort by similarity and return top k\n",
    "        neighbors_with_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        return neighbors_with_sims[:k]\n",
    "    \n",
    "    def propagate_within_service(self, service: str, k: int = 5, threshold: float = 0.7, \n",
    "                               max_iterations: int = 10, min_confidence: float = 0.5, min_threshold: float = 0.1) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Iteratively propagate labels within a single service using Annoy for fast similarity search.\n",
    "        \n",
    "        Args:\n",
    "            service: Service name to propagate within\n",
    "            k: Number of neighbors for k-NN\n",
    "            threshold: Minimum similarity threshold for high-confidence propagation\n",
    "            max_iterations: Maximum number of iterations to perform\n",
    "            min_confidence: Minimum confidence for accepting predictions in later iterations\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of method -> predicted label\n",
    "        \"\"\"\n",
    "        service = service.lower()\n",
    "        predictions = {}\n",
    "        \n",
    "        # Get labeled and unlabeled methods for this service\n",
    "        labeled_methods = [(svc, method) for (svc, method) in self.method_labels.keys() if svc == service]\n",
    "        all_methods = [(service, method) for method in self.service_methods[service]]\n",
    "        unlabeled_methods = [m for m in all_methods if m not in self.method_labels]\n",
    "        \n",
    "        if len(labeled_methods) == 0:\n",
    "            print(f\"‚ö†Ô∏è No labeled methods found for service: {service}\")\n",
    "            return predictions\n",
    "        \n",
    "        print(f\"üîÑ Propagating in {service}: {len(labeled_methods)} labeled ‚Üí {len(unlabeled_methods)} unlabeled\")\n",
    "        \n",
    "        # Ensure we have an index for this service\n",
    "        self._ensure_service_index(service)\n",
    "        \n",
    "        # Create a copy of method_labels to track temporary labels during iteration\n",
    "        temp_method_labels = self.method_labels.copy()\n",
    "        remaining_unlabeled = set(unlabeled_methods)\n",
    "        \n",
    "        # Initialize threshold - will be lowered across iterations if needed\n",
    "        current_threshold = threshold\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            if not remaining_unlabeled:\n",
    "                break\n",
    "                \n",
    "            iteration_predictions = {}\n",
    "            \n",
    "            # For first iteration, use the original threshold\n",
    "            # For later iterations, use min_confidence unless we've lowered it further\n",
    "            if iteration > 0:\n",
    "                current_threshold = min(current_threshold, min_confidence)\n",
    "            \n",
    "            print(f\"üîÑ Iteration {iteration + 1}: {len(remaining_unlabeled)} remaining unlabeled (threshold: {current_threshold:.1f})\")\n",
    "            \n",
    "            # Predict for remaining unlabeled methods\n",
    "            for method_key in list(remaining_unlabeled):\n",
    "                if method_key in self.method_embeddings:\n",
    "                    embedding = self.method_embeddings[method_key]\n",
    "                    \n",
    "                    # Get neighbors with similarities using Annoy\n",
    "                    neighbors_with_sims = self._get_neighbors_with_similarities(service, embedding, k)\n",
    "                    \n",
    "                    # Filter by labeled neighbors (including temporary labels)\n",
    "                    labeled_neighbors = []\n",
    "                    for neighbor_key, similarity in neighbors_with_sims:\n",
    "                        if neighbor_key in temp_method_labels:\n",
    "                            labeled_neighbors.append((neighbor_key, similarity))\n",
    "                    \n",
    "                    if labeled_neighbors:\n",
    "                        # Filter by threshold for high-confidence predictions\n",
    "                        valid_neighbors = [(nk, sim) for nk, sim in labeled_neighbors if sim >= current_threshold]\n",
    "                        \n",
    "                        if valid_neighbors:\n",
    "                            # High-confidence prediction using threshold\n",
    "                            label_weights = defaultdict(float)\n",
    "                            label_counts = defaultdict(int)\n",
    "                            for neighbor_key, similarity in valid_neighbors:\n",
    "                                label = temp_method_labels[neighbor_key]\n",
    "                                label_weights[label] += similarity\n",
    "                                label_counts[label] += 1\n",
    "                            \n",
    "                            predicted_label = max(label_weights, key=label_weights.get)\n",
    "                            total_neighbors = len(valid_neighbors)\n",
    "                            confidence = label_counts[predicted_label] / total_neighbors\n",
    "                            max_similarity = max(sim for _, sim in valid_neighbors)\n",
    "                            \n",
    "                            # Only accept if confidence meets minimum threshold\n",
    "                            if confidence >= min_confidence:\n",
    "                                iteration_predictions[method_key[1]] = {\n",
    "                                    'label': predicted_label,\n",
    "                                    'confidence': confidence,\n",
    "                                    'similarity': max_similarity,\n",
    "                                    'neighbors': [neighbor_key for neighbor_key, _ in valid_neighbors],\n",
    "                                    'iteration': iteration + 1\n",
    "                                }\n",
    "                        elif iteration == max_iterations - 1:\n",
    "                            # Final iteration: use all labeled neighbors regardless of threshold\n",
    "                            label_weights = defaultdict(float)\n",
    "                            label_counts = defaultdict(int)\n",
    "                            for neighbor_key, similarity in labeled_neighbors:\n",
    "                                label = temp_method_labels[neighbor_key]\n",
    "                                label_weights[label] += similarity\n",
    "                                label_counts[label] += 1\n",
    "                            \n",
    "                            predicted_label = max(label_weights, key=label_weights.get)\n",
    "                            total_neighbors = len(labeled_neighbors)\n",
    "                            confidence = label_counts[predicted_label] / total_neighbors\n",
    "                            max_similarity = max(sim for _, sim in labeled_neighbors)\n",
    "                            \n",
    "                            iteration_predictions[method_key[1]] = {\n",
    "                                'label': predicted_label,\n",
    "                                'confidence': confidence,\n",
    "                                'similarity': max_similarity,\n",
    "                                'neighbors': [neighbor_key for neighbor_key, _ in labeled_neighbors],\n",
    "                                'iteration': iteration + 1\n",
    "                            }\n",
    "            \n",
    "            # Add new predictions to results and temporary labels\n",
    "            if iteration_predictions:\n",
    "                predictions.update(iteration_predictions)\n",
    "                print(f\"‚úÖ Added {len(iteration_predictions)} new predictions\")\n",
    "                \n",
    "                # Update temporary labels for next iteration\n",
    "                for method_name, pred_data in iteration_predictions.items():\n",
    "                    method_key = (service, method_name)\n",
    "                    temp_method_labels[method_key] = pred_data['label']\n",
    "                    remaining_unlabeled.discard(method_key)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No new predictions in iteration {iteration + 1}\")\n",
    "                # Lower threshold for next iteration if no predictions made\n",
    "                if iteration < max_iterations - 1:\n",
    "                    current_threshold = max(min_threshold, current_threshold - 0.1)\n",
    "                    if current_threshold == min_threshold:\n",
    "                        print(\"‚ö†Ô∏è Minimum threshold reached, stopping further iterations\")\n",
    "                        break\n",
    "                    print(f\"üìâ Lowering threshold to {current_threshold:.1f}\")\n",
    "\n",
    "        \n",
    "        if remaining_unlabeled:\n",
    "            if iteration == max_iterations:\n",
    "                print(\"‚ö†Ô∏è Maximum number of iterations reached\")\n",
    "            print(f\"‚ö†Ô∏è {len(remaining_unlabeled)} methods remain unlabeled after {iteration+1} iterations\")\n",
    "        else:\n",
    "            print(f\"üéâ All methods labeled after {iteration} iterations!\")\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def propagate_all_services(self, k: int = 5, threshold: float = 0.7, max_iterations: int = 5, min_confidence: float = 0.5, min_threshold: float = 0.1) -> Dict[str, Dict[str, str]]:\n",
    "        \"\"\"Propagate labels for all loaded services.\"\"\"\n",
    "        all_predictions = {}\n",
    "        \n",
    "        for service in self.service_methods.keys():\n",
    "            predictions = self.propagate_within_service(service, k, threshold, max_iterations, min_confidence, min_threshold)\n",
    "            if predictions:\n",
    "                all_predictions[service] = predictions\n",
    "                print(f\"‚úÖ {service}: {len(predictions)} predictions\")\n",
    "        \n",
    "        return all_predictions\n",
    "    \n",
    "    def propagate_cross_service(self, source_service: str, target_service: str, \n",
    "                               k: int = 5, threshold: float = 0.6) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Propagate labels from one service to another using Annoy.\n",
    "        \n",
    "        Args:\n",
    "            source_service: Service with labeled methods to use as training\n",
    "            target_service: Service to predict labels for\n",
    "            k: Number of neighbors for k-NN\n",
    "            threshold: Minimum similarity threshold for propagation\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of method -> predicted label for target service\n",
    "        \"\"\"\n",
    "        source_service = source_service.lower()\n",
    "        target_service = target_service.lower()\n",
    "        predictions = {}\n",
    "        \n",
    "        # Get labeled methods from source service\n",
    "        source_labeled = [(svc, method) for (svc, method) in self.method_labels.keys() if svc == source_service]\n",
    "        \n",
    "        # Get all methods from target service\n",
    "        target_methods = [(target_service, method) for method in self.service_methods[target_service]]\n",
    "        \n",
    "        if len(source_labeled) == 0:\n",
    "            print(f\"‚ö†Ô∏è  No labeled methods found for source service: {source_service}\")\n",
    "            return predictions\n",
    "        \n",
    "        print(f\"üîÄ Cross-service propagation: {source_service} ({len(source_labeled)} labeled) ‚Üí {target_service} ({len(target_methods)} methods)\")\n",
    "        \n",
    "        # Create a temporary combined index for cross-service search\n",
    "        combined_index = AnnoyIndex(self.embedding_dim, 'angular')\n",
    "        source_lookup = {}\n",
    "        \n",
    "        # Add source service embeddings to index\n",
    "        idx = 0\n",
    "        for method_key in source_labeled:\n",
    "            if method_key in self.method_embeddings:\n",
    "                combined_index.add_item(idx, self.method_embeddings[method_key])\n",
    "                source_lookup[idx] = method_key\n",
    "                idx += 1\n",
    "        \n",
    "        combined_index.build(10)\n",
    "        \n",
    "        # Predict for target service methods\n",
    "        for method_key in target_methods:\n",
    "            if method_key in self.method_embeddings and method_key not in self.method_labels:\n",
    "                embedding = self.method_embeddings[method_key]\n",
    "                \n",
    "                # Get neighbors from source service\n",
    "                neighbor_indices = combined_index.get_nns_by_vector(embedding, k)\n",
    "                \n",
    "                # Calculate similarities for all neighbors\n",
    "                all_neighbors = []\n",
    "                for idx in neighbor_indices:\n",
    "                    if idx in source_lookup:\n",
    "                        neighbor_key = source_lookup[idx]\n",
    "                        neighbor_embedding = self.method_embeddings[neighbor_key]\n",
    "                        similarity = cosine_similarity([embedding], [neighbor_embedding])[0][0]\n",
    "                        all_neighbors.append((neighbor_key, similarity))\n",
    "                \n",
    "                if all_neighbors:\n",
    "                    # Filter by threshold for high-confidence predictions\n",
    "                    valid_neighbors = [(nk, sim) for nk, sim in all_neighbors if sim >= threshold]\n",
    "                    \n",
    "                    if valid_neighbors:\n",
    "                        # High-confidence prediction using threshold\n",
    "                        label_weights = defaultdict(float)\n",
    "                        label_counts = defaultdict(int)\n",
    "                        for neighbor_key, similarity in valid_neighbors:\n",
    "                            label = self.method_labels[neighbor_key]\n",
    "                            label_weights[label] += similarity\n",
    "                            label_counts[label] += 1\n",
    "                        \n",
    "                        predicted_label = max(label_weights, key=label_weights.get)\n",
    "                        total_neighbors = len(valid_neighbors)\n",
    "                        confidence = label_counts[predicted_label] / total_neighbors\n",
    "                        max_similarity = max(sim for _, sim in valid_neighbors)\n",
    "                        \n",
    "                        predictions[method_key[1]] = {\n",
    "                            'label': predicted_label,\n",
    "                            'confidence': confidence,\n",
    "                            'similarity': max_similarity,\n",
    "                            'source_neighbors': [neighbor_key for neighbor_key, _ in valid_neighbors]\n",
    "                        }\n",
    "                    else:\n",
    "                        # No neighbors meet threshold, use all neighbors (like sklearn)\n",
    "                        label_weights = defaultdict(float)\n",
    "                        label_counts = defaultdict(int)\n",
    "                        for neighbor_key, similarity in all_neighbors:\n",
    "                            label = self.method_labels[neighbor_key]\n",
    "                            label_weights[label] += similarity\n",
    "                            label_counts[label] += 1\n",
    "                        \n",
    "                        predicted_label = max(label_weights, key=label_weights.get)\n",
    "                        total_neighbors = len(all_neighbors)\n",
    "                        confidence = label_counts[predicted_label] / total_neighbors\n",
    "                        max_similarity = max(sim for _, sim in all_neighbors)\n",
    "                        \n",
    "                        predictions[method_key[1]] = {\n",
    "                            'label': predicted_label,\n",
    "                            'confidence': confidence,\n",
    "                            'similarity': max_similarity,\n",
    "                            'source_neighbors': [neighbor_key for neighbor_key, _ in all_neighbors]\n",
    "                        }\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_propagation(self, test_size: float = 0.3, k: int = 5) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate label propagation using train/test split of manually labeled data.\n",
    "        Note: Uses sklearn for evaluation to maintain compatibility with existing metrics.\n",
    "        \"\"\"\n",
    "        if len(self.method_labels) < 10:\n",
    "            print(\"‚ö†Ô∏è Not enough labeled data for evaluation\")\n",
    "            return {}\n",
    "        \n",
    "        # Prepare data\n",
    "        methods = list(self.method_labels.keys())\n",
    "        X = np.array([self.method_embeddings[method] for method in methods])\n",
    "        y = [self.method_labels[method] for method in methods]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test, methods_train, methods_test = train_test_split(\n",
    "            X, y, methods, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # For evaluation, create a temporary Annoy index with training data\n",
    "        eval_index = AnnoyIndex(self.embedding_dim, 'angular')\n",
    "        train_lookup = {}\n",
    "        \n",
    "        for idx, (embedding, label) in enumerate(zip(X_train, y_train)):\n",
    "            eval_index.add_item(idx, embedding)\n",
    "            train_lookup[idx] = label\n",
    "        \n",
    "        eval_index.build(10)\n",
    "        \n",
    "        # Predict using Annoy\n",
    "        y_pred = []\n",
    "        for test_embedding in X_test:\n",
    "            neighbor_indices = eval_index.get_nns_by_vector(test_embedding, k)\n",
    "            \n",
    "            # Vote based on neighbors\n",
    "            label_votes = defaultdict(int)\n",
    "            for idx in neighbor_indices:\n",
    "                if idx in train_lookup:\n",
    "                    label_votes[train_lookup[idx]] += 1\n",
    "            \n",
    "            if label_votes:\n",
    "                predicted_label = max(label_votes, key=label_votes.get)\n",
    "                y_pred.append(predicted_label)\n",
    "            else:\n",
    "                y_pred.append('none')  # Default prediction\n",
    "        \n",
    "        # Calculate metrics\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        print(\"üéØ Evaluation Results:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Use visualization utility for confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred, 'Label Propagation - Confusion Matrix (Annoy)')\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def find_optimal_k(self, k_values: List[int] = [3, 5, 7, 10]) -> int:\n",
    "        \"\"\"Find optimal k value using cross-validation with Annoy.\"\"\"\n",
    "        if len(self.method_labels) < 10:\n",
    "            print(\"‚ö†Ô∏è Not enough labeled data for k optimization\")\n",
    "            return 5\n",
    "        \n",
    "        methods = list(self.method_labels.keys())\n",
    "        X = np.array([self.method_embeddings[method] for method in methods])\n",
    "        y = [self.method_labels[method] for method in methods]\n",
    "        \n",
    "        best_k = 5\n",
    "        best_score = 0\n",
    "        \n",
    "        print(\"üîç Finding optimal k value:\")\n",
    "        for k in k_values:\n",
    "            if k < len(set(y)):  # Ensure k is less than number of classes\n",
    "                # Use sklearn for cross-validation (simpler for this evaluation)\n",
    "                knn = KNeighborsClassifier(n_neighbors=min(k, len(X)-1), metric='cosine')\n",
    "                scores = cross_val_score(knn, X, y, cv=min(5, len(X)//2), scoring='f1_macro')\n",
    "                avg_score = scores.mean()\n",
    "                print(f\"  k={k}: F1-score = {avg_score:.3f} ¬± {scores.std():.3f}\")\n",
    "                \n",
    "                if avg_score > best_score:\n",
    "                    best_score = avg_score\n",
    "                    best_k = k\n",
    "        \n",
    "        print(f\"‚úÖ Best k value: {best_k} (F1-score: {best_score:.3f})\")\n",
    "        return best_k\n",
    "    \n",
    "    def analyze_label_distribution(self) -> None:\n",
    "        \"\"\"Analyze the distribution of labels across services.\"\"\"\n",
    "        service_label_counts = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for (service, method), label in self.method_labels.items():\n",
    "            service_label_counts[service][label] += 1\n",
    "        \n",
    "        print(\"üìä Label Distribution by Service:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for service, label_counts in service_label_counts.items():\n",
    "            total = sum(label_counts.values())\n",
    "            print(f\"{service.upper()}:\")\n",
    "            for label, count in label_counts.items():\n",
    "                percentage = (count / total) * 100\n",
    "                print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "            print()\n",
    "    \n",
    "    def analyze_method_coverage(self) -> None:\n",
    "        \"\"\"Analyze method coverage across services.\"\"\"\n",
    "        print(\"üìà Method Coverage Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for service, methods in self.service_methods.items():\n",
    "            labeled_count = len([m for m in methods if (service, m) in self.method_labels])\n",
    "            total_count = len(methods)\n",
    "            unlabeled_count = total_count - labeled_count\n",
    "            coverage = (labeled_count / total_count) * 100 if total_count > 0 else 0\n",
    "            \n",
    "            print(f\"{service.upper()}:\")\n",
    "            print(f\"üìä {labeled_count}/{total_count} labeled ({coverage:.1f}% coverage)\")\n",
    "            print(f\"üîç {unlabeled_count} methods need propagation\")\n",
    "        print()\n",
    "    \n",
    "    def get_similar_services(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Get suggested similar services for cross-service propagation.\"\"\"\n",
    "        similar_services = {\n",
    "            's3': ['efs', 'fsx', 'backup'],  # Storage services\n",
    "            'dynamodb': ['rds', 'elasticache', 'neptune', 'documentdb'],  # Database services  \n",
    "            'lambda': ['ecs', 'batch', 'stepfunctions'],  # Compute services\n",
    "            'sqs': ['sns', 'eventbridge', 'kinesis', 'mq'],  # Messaging services\n",
    "            'iam': ['sts', 'ssm', 'cloudwatch'],  # Management services\n",
    "            'ec2': ['autoscaling', 'elb', 'ecs'],  # Infrastructure services\n",
    "            'sns': ['sqs', 'eventbridge', 'pinpoint'],  # Messaging services\n",
    "            'ssm': ['iam', 'cloudwatch', 'config']  # Management services\n",
    "        }\n",
    "        \n",
    "        return similar_services\n",
    "    \n",
    "    def save_predictions(self, predictions: Dict[str, Dict[str, str]], \n",
    "                        output_file: Path, metadata: Dict = None) -> None:\n",
    "        \"\"\"Save predictions to JSON file.\"\"\"\n",
    "        # Convert to serializable format\n",
    "        serializable_predictions = {}\n",
    "        for service, service_predictions in predictions.items():\n",
    "            serializable_predictions[service] = {}\n",
    "            for method, pred_data in service_predictions.items():\n",
    "                if isinstance(pred_data, dict):\n",
    "                    # Convert numpy types to native Python types\n",
    "                    serializable_pred = {}\n",
    "                    for key, value in pred_data.items():\n",
    "                        if isinstance(value, np.floating):\n",
    "                            serializable_pred[key] = float(value)\n",
    "                        elif isinstance(value, list):\n",
    "                            serializable_pred[key] = [str(item) for item in value]\n",
    "                        else:\n",
    "                            serializable_pred[key] = value\n",
    "                    serializable_predictions[service][method] = serializable_pred\n",
    "                else:\n",
    "                    serializable_predictions[service][method] = pred_data\n",
    "        \n",
    "        # Add metadata if provided\n",
    "        if metadata:\n",
    "            output_data = {\n",
    "                'metadata': metadata,\n",
    "                'predictions': serializable_predictions\n",
    "            }\n",
    "        else:\n",
    "            output_data = serializable_predictions\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(output_data, f, indent=2)\n",
    "        \n",
    "        print(f\"üíæ Predictions saved to: {output_file}\")\n",
    "    \n",
    "    def save_indexes(self, index_dir: Path) -> None:\n",
    "        \"\"\"Save Annoy indexes for fast loading.\"\"\"\n",
    "        index_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for service, index in self.annoy_indexes.items():\n",
    "            # Save Annoy index\n",
    "            index_path = index_dir / f\"{service}_index.ann\"\n",
    "            index.save(str(index_path))\n",
    "            \n",
    "            # Save lookup table\n",
    "            lookup_path = index_dir / f\"{service}_lookup.pkl\"\n",
    "            with open(lookup_path, 'wb') as f:\n",
    "                pickle.dump(self.method_lookups[service], f)\n",
    "        \n",
    "        print(f\"üíæ Annoy indexes saved to: {index_dir}\")\n",
    "    \n",
    "    def load_indexes(self, index_dir: Path) -> None:\n",
    "        \"\"\"Load pre-built Annoy indexes.\"\"\"\n",
    "        if not index_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Index directory not found: {index_dir}\")\n",
    "            return\n",
    "            \n",
    "        for service in self.service_methods.keys():\n",
    "            index_path = index_dir / f\"{service}_index.ann\"\n",
    "            lookup_path = index_dir / f\"{service}_lookup.pkl\"\n",
    "            \n",
    "            if index_path.exists() and lookup_path.exists():\n",
    "                # Load Annoy index\n",
    "                index = AnnoyIndex(self.embedding_dim, 'angular')\n",
    "                index.load(str(index_path))\n",
    "                \n",
    "                # Load lookup table\n",
    "                with open(lookup_path, 'rb') as f:\n",
    "                    lookup = pickle.load(f)\n",
    "                \n",
    "                self.annoy_indexes[service] = index\n",
    "                self.method_lookups[service] = lookup\n",
    "                \n",
    "                print(f\"üìÇ Loaded Annoy index for {service}: {len(lookup)} methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d3af52f-41b2-41a5-8cb3-03c20bc70b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ AWS API Label Propagation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configuration - Paths relative to the notebook location\n",
    "project_root = Path(\"..\")\n",
    "embeddings_dir = project_root / \"embeddings\"\n",
    "labels_file = project_root / \"labels.csv\"\n",
    "\n",
    "# Services with manual labels\n",
    "labeled_services = ['S3', 'DynamoDB', 'Lambda', 'EC2', 'IAM', 'SSM', 'SQS', 'SNS']\n",
    "\n",
    "print(f\"üìÅ Embeddings directory: {embeddings_dir}\")\n",
    "print(f\"üè∑Ô∏è Labels file: {labels_file}\")\n",
    "print(f\"üìä Labeled services: {', '.join(labeled_services)}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not embeddings_dir.exists():\n",
    "    print(f\"‚ö†Ô∏è Warning: Embeddings directory not found at {embeddings_dir}\")\n",
    "    print(f\"Current working directory: {Path.cwd()}\")\n",
    "    print(f\"Looking for: {embeddings_dir.absolute()}\")\n",
    "    \n",
    "if not labels_file.exists():\n",
    "    print(f\"‚ö†Ô∏è Warning: Labels file not found at {labels_file}\")\n",
    "    print(f\"Current working directory: {Path.cwd()}\")\n",
    "    print(f\"Looking for: {labels_file.absolute()}\")\n",
    "\n",
    "if embeddings_dir.exists() and labels_file.exists():\n",
    "    print(\"‚úÖ All required files and directories found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b591c26-d4fc-41e8-9d0d-b9d8b93a2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 1: Loading Data\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "propagator = AWSLabelPropagator(embeddings_dir, labels_file, embedding_format=\"with_service_params\")\n",
    "\n",
    "# Set embedding dimension for Qwen3-0.6B default\n",
    "propagator.set_embedding_dimension(1024)\n",
    "\n",
    "# Load embeddings\n",
    "propagator.load_method_embeddings(labeled_services)\n",
    "\n",
    "# Handle Annoy indexes\n",
    "annoy_indexes_dir = embeddings_dir / \"annoy_indexes\"\n",
    "\n",
    "# Try to load existing indexes if they exist\n",
    "if annoy_indexes_dir.exists():\n",
    "    print(f\"üìÇ Loading existing Annoy indexes from {annoy_indexes_dir}\")\n",
    "    propagator.load_indexes(annoy_indexes_dir)\n",
    "else:\n",
    "    print(f\"üìÅ Creating new Annoy indexes directory: {annoy_indexes_dir}\")\n",
    "    annoy_indexes_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf577955-b797-4e55-a58b-08a307d2a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 2: Data Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "propagator.analyze_label_distribution()\n",
    "propagator.analyze_method_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7ee5612-dca3-4e2d-ae4e-890f55867f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Parameter Tuning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 3: Model Evaluation and Parameter Tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find optimal k value\n",
    "best_k = propagator.find_optimal_k([3, 5, 7, 10])\n",
    "\n",
    "# Detailed evaluation with train/test split\n",
    "if len(propagator.method_labels) >= 10:\n",
    "    evaluation_results = propagator.evaluate_propagation(k=best_k)\n",
    "    \n",
    "    # Use visualization utility for evaluation summary\n",
    "    print_evaluation_summary(\n",
    "        evaluation_results, \n",
    "        best_k, \n",
    "        len(propagator.method_labels), \n",
    "        0  # Will be updated after predictions\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough labeled data for detailed evaluation\")\n",
    "    evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c184e802-619c-4e32-810c-7a4afabae749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 4: Within-Service Label Propagation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test different similarity thresholds\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8]\n",
    "results_by_threshold = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\nüîÑ Testing similarity threshold: {threshold}\")\n",
    "    predictions = propagator.propagate_all_services(k=best_k, threshold=threshold, max_iterations=30, min_confidence=0.5, min_threshold=0.1)\n",
    "\n",
    "    total_predictions = sum(len(pred) for pred in predictions.values())\n",
    "    results_by_threshold[threshold] = {\n",
    "        'predictions': predictions,\n",
    "        'total_count': total_predictions\n",
    "    }\n",
    "    print(f\"üìä Total predictions: {total_predictions}\")\n",
    "    \n",
    "    # Use visualization utility for service predictions summary\n",
    "    print_service_predictions_summary(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09ed02e3-41b4-4e6b-b6fa-8991b68bafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 5: Threshold Analysis and Visualization\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Visualize threshold analysis\n",
    "plot_threshold_analysis(results_by_threshold, \"Threshold Impact on Predictions\")\n",
    "\n",
    "# Choose best threshold (you can adjust this based on analysis above)\n",
    "chosen_threshold = 0.6  # Balance between quantity and quality\n",
    "final_predictions = results_by_threshold[chosen_threshold]['predictions']\n",
    "\n",
    "print(f\"‚úÖ Using threshold: {chosen_threshold}\")\n",
    "print(f\"üìä Final within-service predictions: {sum(len(pred) for pred in final_predictions.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e98839a5-0d1f-43af-9269-b8928ae5eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 6: Cross-Service Propagation Testing\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get similar services suggestions\n",
    "similar_services = propagator.get_similar_services()\n",
    "\n",
    "print(\"üîÄ Testing cross-service propagation for similar services:\")\n",
    "\n",
    "cross_service_predictions = {}\n",
    "cross_service_tests = [\n",
    "    ('s3', 'efs'),\n",
    "    ('dynamodb', 'rds'), \n",
    "    ('sqs', 'eventbridge'),\n",
    "    ('iam', 'sts')\n",
    "]\n",
    "\n",
    "for source_service, target_service in cross_service_tests:\n",
    "    if (source_service in propagator.service_methods and \n",
    "        target_service in propagator.service_methods):\n",
    "        \n",
    "        print(f\"\\nüîÄ Testing: {source_service} ‚Üí {target_service}\")\n",
    "        cross_pred = propagator.propagate_cross_service(\n",
    "            source_service, target_service, k=best_k, threshold=0.5\n",
    "        )\n",
    "        \n",
    "        if cross_pred:\n",
    "            cross_service_predictions[f\"{source_service}_to_{target_service}\"] = cross_pred\n",
    "            \n",
    "            # Use visualization utility for cross-service summary\n",
    "            print_service_predictions_summary({f\"{source_service}_to_{target_service}\": cross_pred})\n",
    "        else:\n",
    "            print(f\"‚ùå No predictions made (low similarity or no data)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4d062cd-a1f1-4e68-87e8-66d367aff8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 7: Comprehensive Visualization Dashboard\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comprehensive visualization dashboard\n",
    "create_results_dashboard(\n",
    "    final_predictions,\n",
    "    evaluation_results,\n",
    "    results_by_threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "692b1cbb-ebea-443f-a96a-f2737f416bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 8: Saving Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save within-service predictions\n",
    "within_service_file = project_root / \"within_service_predictions.json\"\n",
    "within_service_metadata = {\n",
    "    'type': 'within_service_propagation',\n",
    "    'embedding_format': propagator.embedding_format,\n",
    "    'k_neighbors': best_k,\n",
    "    'similarity_threshold': chosen_threshold,\n",
    "    'labeled_services': labeled_services,\n",
    "    'total_labeled_methods': len(propagator.method_labels),\n",
    "    'total_predictions': sum(len(pred) for pred in final_predictions.values())\n",
    "}\n",
    "\n",
    "propagator.save_predictions(final_predictions, within_service_file, within_service_metadata)\n",
    "\n",
    "# Save cross-service predictions if any\n",
    "if cross_service_predictions:\n",
    "    cross_service_file = project_root / \"cross_service_predictions.json\"\n",
    "    cross_service_metadata = {\n",
    "        'type': 'cross_service_propagation',\n",
    "        'embedding_format': propagator.embedding_format,\n",
    "        'k_neighbors': best_k,\n",
    "        'similarity_threshold': 0.5,  # Used for cross-service\n",
    "        'total_predictions': sum(len(pred) for pred in cross_service_predictions.values())\n",
    "    }\n",
    "    \n",
    "    propagator.save_predictions(cross_service_predictions, cross_service_file, cross_service_metadata)\n",
    "\n",
    "# Save visualization summary\n",
    "viz_summary_file = project_root / \"visualization_summary.json\"\n",
    "save_visualization_summary(final_predictions, viz_summary_file, within_service_metadata)\n",
    "\n",
    "# Generate comprehensive summary\n",
    "summary = {\n",
    "    'experiment_metadata': {\n",
    "        'embedding_format': propagator.embedding_format,\n",
    "        'optimal_k': best_k,\n",
    "        'within_service_threshold': chosen_threshold,\n",
    "        'cross_service_threshold': 0.5,\n",
    "        'labeled_services': labeled_services,\n",
    "        'total_labeled_methods': len(propagator.method_labels),\n",
    "        'evaluation_results': evaluation_results\n",
    "    },\n",
    "    'within_service_results': {\n",
    "        'total_predictions': sum(len(pred) for pred in final_predictions.values()),\n",
    "        'predictions_by_service': {}\n",
    "    },\n",
    "    'cross_service_results': {\n",
    "        'total_predictions': sum(len(pred) for pred in cross_service_predictions.values()),\n",
    "        'successful_transfers': list(cross_service_predictions.keys())\n",
    "    },\n",
    "    'recommendations': {\n",
    "        'high_confidence_services': [],\n",
    "        'manual_review_needed': [],\n",
    "        'next_similar_services': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analyze within-service results for recommendations\n",
    "for service, predictions in final_predictions.items():\n",
    "    service_summary = {\n",
    "        'total_predictions': len(predictions),\n",
    "        'label_distribution': {},\n",
    "        'avg_confidence': 0,\n",
    "        'high_confidence_count': 0\n",
    "    }\n",
    "    \n",
    "    total_conf = 0\n",
    "    for method, pred_data in predictions.items():\n",
    "        label = pred_data['label']\n",
    "        confidence = pred_data['confidence']\n",
    "        \n",
    "        service_summary['label_distribution'][label] = service_summary['label_distribution'].get(label, 0) + 1\n",
    "        total_conf += confidence\n",
    "        \n",
    "        if confidence > 0.8:\n",
    "            service_summary['high_confidence_count'] += 1\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        service_summary['avg_confidence'] = total_conf / len(predictions)\n",
    "        \n",
    "        # Add to recommendations\n",
    "        if service_summary['avg_confidence'] > 0.7 and len(predictions) >= 5:\n",
    "            summary['recommendations']['high_confidence_services'].append(service)\n",
    "        \n",
    "        low_conf_count = len(predictions) - service_summary['high_confidence_count']\n",
    "        if low_conf_count > len(predictions) * 0.3:  # More than 30% low confidence\n",
    "            summary['recommendations']['manual_review_needed'].append(service)\n",
    "    \n",
    "    summary['within_service_results']['predictions_by_service'][service] = service_summary\n",
    "\n",
    "# Add similar services recommendations\n",
    "for service in labeled_services:\n",
    "    if service.lower() in similar_services:\n",
    "        summary['recommendations']['next_similar_services'][service] = similar_services[service.lower()]\n",
    "\n",
    "# Save summary\n",
    "summary_file = project_root / \"propagation_summary.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Summary saved to: {summary_file}\")\n",
    "\n",
    "# Save Annoy indexes after building\n",
    "print(\"\\nüíæ Saving Annoy indexes...\")\n",
    "propagator.save_indexes(annoy_indexes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "113a2967-b087-4794-82e0-acaf922e3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use visualization utility for final summary\n",
    "print_evaluation_summary(\n",
    "    evaluation_results, \n",
    "    best_k, \n",
    "    len(propagator.method_labels), \n",
    "    sum(len(pred) for pred in final_predictions.values())\n",
    ")\n",
    "\n",
    "print(f\"üéâ Label propagation complete!\")\n",
    "print(f\"üìä Within-service predictions: {sum(len(pred) for pred in final_predictions.values())}\")\n",
    "if cross_service_predictions:\n",
    "    print(f\"üîÄ Cross-service predictions: {sum(len(pred) for pred in cross_service_predictions.values())}\")\n",
    "\n",
    "print(\"üéØ Next Steps Recommendations:\")\n",
    "\n",
    "print(\"1. ‚úÖ High-confidence services (ready for use):\")\n",
    "for service in summary['recommendations']['high_confidence_services']:\n",
    "    pred_count = len(final_predictions.get(service, {}))\n",
    "    avg_conf = summary['within_service_results']['predictions_by_service'][service]['avg_confidence']\n",
    "    print(f\"   ‚Ä¢ {service}: {pred_count} predictions, {avg_conf:.3f} avg confidence\")\n",
    "\n",
    "print(\"2. ‚ö†Ô∏è  Services needing manual review:\")\n",
    "for service in summary['recommendations']['manual_review_needed']:\n",
    "    pred_count = len(final_predictions.get(service, {}))\n",
    "    print(f\"   ‚Ä¢ {service}: {pred_count} predictions (review low-confidence ones)\")\n",
    "\n",
    "print(\"3. üîÄ Recommended similar services for cross-service propagation:\")\n",
    "for source_service, similar_list in summary['recommendations']['next_similar_services'].items():\n",
    "    if similar_list:\n",
    "        print(f\"   ‚Ä¢ {source_service} ‚Üí {', '.join(similar_list)}\")\n",
    "\n",
    "print(\"4. üìÅ Files generated:\")\n",
    "print(f\"   ‚Ä¢ {within_service_file.name} - Within-service predictions\")\n",
    "if cross_service_predictions:\n",
    "    print(f\"   ‚Ä¢ {cross_service_file.name} - Cross-service predictions\")\n",
    "print(f\"   ‚Ä¢ {summary_file.name} - Complete analysis summary\")\n",
    "print(f\"   ‚Ä¢ {viz_summary_file.name} - Visualization data summary\")\n",
    "print(f\"   ‚Ä¢ {annoy_indexes_dir.name}/ - Annoy indexes for fast similarity search\")\n",
    "\n",
    "print(f\"üéä Process complete! Review the generated files and high-confidence predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
