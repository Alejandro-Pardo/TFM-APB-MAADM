{
  "method_name": "retrieve_and_generate",
  "url": "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve_and_generate.html",
  "description": "Queries a knowledge base and generates responses based on the retrieved results and using the specified foundation model or inference profile. The response only cites sources that are relevant to the query.",
  "parameters": [
    {
      "name": "input",
      "type": "dict",
      "required": true,
      "description": "Contains the query to be made to the knowledge base. The query made to the knowledge base.",
      "nested_params": [
        {
          "name": "text",
          "type": "string",
          "required": false,
          "description": "The query made to the knowledge base.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "retrieveAndGenerateConfiguration",
      "type": "dict",
      "required": true,
      "description": "Contains configurations for the knowledge base query and retrieval process. For more information, see Query configurations. externalSourcesConfiguration (dict) --- The configuration for the external source wrapper object in the retrieveAndGenerate function. generationConfiguration (dict) --- The prompt used with the external source wrapper object with the retrieveAndGenerate function. additionalModelRequestFields (dict) --- Additional model parameters and their corresponding values not included in the textInferenceConfig structure for an external source. Takes in custom model parameters specific to the language model being used. (string) --- (document) --- guardrailConfiguration (dict) --- The configuration details for the guardrail. The unique identifier for the guardrail. The version of the guardrail. inferenceConfig (dict) --- Configuration settings for inference when using RetrieveAndGenerate to generate responses while using an external source. textInferenceConfig (dict) --- Configuration settings specific to text generation while generating responses using RetrieveAndGenerate. maxTokens (integer) --- The maximum number of tokens to generate in the output text. Do not use the minimum of 0 or the maximum of 65536. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model. stopSequences (list) --- A list of sequences of characters that, if generated, will cause the model to stop generating further tokens. Do not use a minimum length of 1 or a maximum length of 1000. (string) --- temperature (float) --- Controls the random-ness of text generated by the language model, influencing how much the model sticks to the most predictable next words versus exploring more surprising options. A lower temperature value (e.g. 0.2 or 0.3) makes model outputs more deterministic or predictable, while a higher temperature (e.g. 0.8 or 0.9) makes the outputs more creative or unpredictable. topP (float) --- A probability distribution threshold which controls what the model considers for the set of possible next tokens. The model will only consider the top p% of the probability distribution when generating the next token. performanceConfig (dict) --- The latency configuration for the model. latency (string) --- To use a latency-optimized version of the model, set to optimized. promptTemplate (dict) --- Contain the textPromptTemplate string for the external source wrapper object. textPromptTemplate (string) --- The template for the prompt that's sent to the model for response generation. You can include prompt placeholders, which become replaced before the prompt is sent to the model to provide instructions and context to the model. In addition, you can include XML tags to delineate meaningful sections of the prompt template. For more information, see the following resources: Knowledge base prompt templates Use XML tags with Anthropic Claude models The model Amazon Resource Name (ARN) for the external source wrapper object in the retrieveAndGenerate function. The document for the external source wrapper object in the retrieveAndGenerate function. (dict) --- The unique external source of the content contained in the wrapper object. byteContent (dict) --- The identifier, contentType, and data of the external source wrapper object. The MIME type of the document contained in the wrapper object. The byte value of the file to upload, encoded as a Base-64 string. The file name of the document contained in the wrapper object. s3Location (dict) --- The S3 location of the external source wrapper object. The file location of the S3 wrapper object. The source type of the external source wrapper object. knowledgeBaseConfiguration (dict) --- Contains details about the knowledge base for retrieving information and generating responses. generationConfiguration (dict) --- Contains configurations for response generation based on the knowledge base query results. additionalModelRequestFields (dict) --- Additional model parameters and corresponding values not included in the textInferenceConfig structure for a knowledge base. This allows users to provide custom model parameters specific to the language model being used. inferenceConfig (dict) --- Configuration settings for inference when using RetrieveAndGenerate to generate responses while using a knowledge base as a source. promptTemplate (dict) --- Contains the template for the prompt that's sent to the model for response generation. Generation prompts must include the $search_results$ variable. For more information, see Use placeholder variables in the user guide. For more information, see the following resources: Knowledge base prompt templates Use XML tags with Anthropic Claude models The unique identifier of the knowledge base that is queried. The ARN of the foundation model or inference profile used to generate a response. orchestrationConfiguration (dict) --- Settings for how the model processes the prompt prior to retrieval and generation. (string) --- (document) --- inferenceConfig (dict) --- Configuration settings for inference when using RetrieveAndGenerate to generate responses while using a knowledge base as a source. promptTemplate (dict) --- Contains the template for the prompt that's sent to the model. Orchestration prompts must include the $conversation_history$ and $output_format_instructions$ variables. For more information, see the following resources: Knowledge base prompt templates Use XML tags with Anthropic Claude models queryTransformationConfiguration (dict) --- To split up the prompt and retrieve multiple sources, set the transformation type to QUERY_DECOMPOSITION. The type of transformation to apply to the prompt. retrievalConfiguration (dict) --- Contains configurations for how to retrieve and return the knowledge base query. Contains details about how the results from the vector search should be returned. filter (dict) --- Specifies the filters to use on the metadata in the knowledge base data sources before returning results. andAll (list) --- Knowledge base data sources are returned if their metadata attributes fulfill all the filter conditions inside this list. (dict) --- Specifies the filters to use on the metadata attributes in the knowledge base data sources before returning results. See the examples below to see how to use these filters. This data type is used in the following API operations: Retrieve request --- in the filter field RetrieveAndGenerate request --- in the filter field equals (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value matches the value in this object. The following example would return data sources with an animal attribute whose value is cat: \"equals\": { \"key\": \"animal\", \"value\": \"cat\" } The name that the metadata attribute must match. The value to whcih to compare the value of the metadata attribute. greaterThan (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is greater than the value in this object. The following example would return data sources with an year attribute whose value is greater than 1989: \"greaterThan\": { \"key\": \"year\", \"value\": 1989 } The name that the metadata attribute must match. greaterThanOrEquals (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is greater than or equal to the value in this object. The following example would return data sources with an year attribute whose value is greater than or equal to 1989: \"greaterThanOrEquals\": { \"key\": \"year\", \"value\": 1989 } The name that the metadata attribute must match. in (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is in the list specified in the value in this object. The following example would return data sources with an animal attribute that is either cat or dog: \"in\": { \"key\": \"animal\", \"value\": [\"cat\", \"dog\"] } The name that the metadata attribute must match. lessThan (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is less than the value in this object. The following example would return data sources with an year attribute whose value is less than to 1989. \"lessThan\": { \"key\": \"year\", \"value\": 1989 } The name that the metadata attribute must match. lessThanOrEquals (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is less than or equal to the value in this object. The following example would return data sources with an year attribute whose value is less than or equal to 1989. \"lessThanOrEquals\": { \"key\": \"year\", \"value\": 1989 } The name that the metadata attribute must match. listContains (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is a list that contains the value as one of its members. The following example would return data sources with an animals attribute that is a list containing a cat member (for example [\"dog\", \"cat\"]). \"listContains\": { \"key\": \"animals\", \"value\": \"cat\" } The name that the metadata attribute must match. notEquals (dict) --- Knowledge base data sources are returned when: It contains a metadata attribute whose name matches the key and whose value doesn't match the value in this object. The key is not present in the document. The following example would return data sources that don't contain an animal attribute whose value is cat. \"notEquals\": { \"key\": \"animal\", \"value\": \"cat\" } The name that the metadata attribute must match. notIn (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value isn't in the list specified in the value in this object. The following example would return data sources whose animal attribute is neither cat nor dog. \"notIn\": { \"key\": \"animal\", \"value\": [\"cat\", \"dog\"] } The name that the metadata attribute must match. orAll (list) --- Knowledge base data sources are returned if their metadata attributes fulfill at least one of the filter conditions inside this list. This data type is used in the following API operations: Retrieve request --- in the filter field RetrieveAndGenerate request --- in the filter field startsWith (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value starts with the value in this object. This filter is currently only supported for Amazon OpenSearch Serverless vector stores. The following example would return data sources with an animal attribute starts with ca (for example, cat or camel). \"startsWith\": { \"key\": \"animal\", \"value\": \"ca\" } The name that the metadata attribute must match. stringContains (dict) --- Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is one of the following: A string that contains the value as a substring. The following example would return data sources with an animal attribute that contains the substring at (for example cat). \"stringContains\": { \"key\": \"animal\", \"value\": \"at\" } A list with a member that contains the value as a substring. The following example would return data sources with an animals attribute that is a list containing a member that contains the substring at (for example [\"dog\", \"cat\"]). \"stringContains\": { \"key\": \"animals\", \"value\": \"at\" } The name that the metadata attribute must match. implicitFilterConfiguration (dict) --- Settings for implicit filtering. Metadata that can be used in a filter. (dict) --- Details about a metadata attribute. The attribute's description. The attribute's key. The attribute's type. The model that generates the filter. numberOfResults (integer) --- The number of source chunks to retrieve. overrideSearchType (string) --- By default, Amazon Bedrock decides a search strategy for you. If you're using an Amazon OpenSearch Serverless vector store that contains a filterable text field, you can specify whether to query the knowledge base with a HYBRID search using both vector embeddings and raw text, or SEMANTIC search using only vector embeddings. For other vector store configurations, only SEMANTIC search is available. For more information, see Test a knowledge base. rerankingConfiguration (dict) --- Contains configurations for reranking the retrieved results. For more information, see Improve the relevance of query responses with a reranker model. bedrockRerankingConfiguration (dict) --- Contains configurations for an Amazon Bedrock reranker model. metadataConfiguration (dict) --- Contains configurations for the metadata to use in reranking. Specifies whether to consider all metadata when reranking, or only the metadata that you select. If you specify SELECTIVE, include the selectiveModeConfiguration field. selectiveModeConfiguration (dict) --- Contains configurations for the metadata fields to include or exclude when considering reranking. fieldsToExclude (list) --- An array of objects, each of which specifies a metadata field to exclude from consideration when reranking. (dict) --- Contains information for a metadata field to include in or exclude from consideration when reranking. The name of a metadata field to include in or exclude from consideration when reranking. fieldsToInclude (list) --- An array of objects, each of which specifies a metadata field to include in consideration when reranking. The remaining metadata fields are ignored. Contains configurations for the reranker model. additionalModelRequestFields (dict) --- A JSON object whose keys are request fields for the model and whose values are values for those fields. (string) --- (document) --- The ARN of the reranker model to use. numberOfRerankedResults (integer) --- The number of results to return after reranking. The type of reranker model. The type of resource that contains your data for retrieving information and generating responses.",
      "nested_params": [
        {
          "name": "externalSourcesConfiguration",
          "type": "dict",
          "required": false,
          "description": "The configuration for the external source wrapper object in the retrieveAndGenerate function.",
          "nested_params": [
            {
              "name": "generationConfiguration",
              "type": "dict",
              "required": false,
              "description": "The prompt used with the external source wrapper object with the retrieveAndGenerate function.",
              "nested_params": [
                {
                  "name": "additionalModelRequestFields",
                  "type": "dict",
                  "required": false,
                  "description": "Additional model parameters and their corresponding values not included in the textInferenceConfig structure for an external source. Takes in custom model parameters specific to the language model being used.",
                  "nested_params": []
                },
                {
                  "name": "guardrailConfiguration",
                  "type": "dict",
                  "required": false,
                  "description": "The configuration details for the guardrail.",
                  "nested_params": [
                    {
                      "name": "guardrailId",
                      "type": "string",
                      "required": false,
                      "description": "The unique identifier for the guardrail.",
                      "nested_params": []
                    },
                    {
                      "name": "guardrailVersion",
                      "type": "string",
                      "required": false,
                      "description": "The version of the guardrail.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "inferenceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "Configuration settings for inference when using RetrieveAndGenerate to generate responses while using an external source.",
                  "nested_params": [
                    {
                      "name": "textInferenceConfig",
                      "type": "dict",
                      "required": false,
                      "description": "Configuration settings specific to text generation while generating responses using RetrieveAndGenerate.",
                      "nested_params": [
                        {
                          "name": "maxTokens",
                          "type": "integer",
                          "required": false,
                          "description": "The maximum number of tokens to generate in the output text. Do not use the minimum of 0 or the maximum of 65536. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "stopSequences",
                          "type": "list",
                          "required": false,
                          "description": "A list of sequences of characters that, if generated, will cause the model to stop generating further tokens. Do not use a minimum length of 1 or a maximum length of 1000. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "temperature",
                          "type": "float",
                          "required": false,
                          "description": "Controls the random-ness of text generated by the language model, influencing how much the model sticks to the most predictable next words versus exploring more surprising options. A lower temperature value (e.g. 0.2 or 0.3) makes model outputs more deterministic or predictable, while a higher temperature (e.g. 0.8 or 0.9) makes the outputs more creative or unpredictable.",
                          "nested_params": []
                        },
                        {
                          "name": "topP",
                          "type": "float",
                          "required": false,
                          "description": "A probability distribution threshold which controls what the model considers for the set of possible next tokens. The model will only consider the top p% of the probability distribution when generating the next token.",
                          "nested_params": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "name": "performanceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "The latency configuration for the model.",
                  "nested_params": [
                    {
                      "name": "latency",
                      "type": "string",
                      "required": false,
                      "description": "To use a latency-optimized version of the model, set to optimized.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "promptTemplate",
                  "type": "dict",
                  "required": false,
                  "description": "Contain the textPromptTemplate string for the external source wrapper object.",
                  "nested_params": [
                    {
                      "name": "textPromptTemplate",
                      "type": "string",
                      "required": false,
                      "description": "The template for the prompt that's sent to the model for response generation. You can include prompt placeholders, which become replaced before the prompt is sent to the model to provide instructions and context to the model. In addition, you can include XML tags to delineate meaningful sections of the prompt template. For more information, see the following resources:",
                      "nested_params": []
                    }
                  ]
                }
              ]
            },
            {
              "name": "modelArn",
              "type": "string",
              "required": false,
              "description": "The model Amazon Resource Name (ARN) for the external source wrapper object in the retrieveAndGenerate function.",
              "nested_params": []
            },
            {
              "name": "sources",
              "type": "list",
              "required": false,
              "description": "The document for the external source wrapper object in the retrieveAndGenerate function.",
              "nested_params": [
                {
                  "name": "byteContent",
                  "type": "dict",
                  "required": false,
                  "description": "The identifier, contentType, and data of the external source wrapper object.",
                  "nested_params": [
                    {
                      "name": "contentType",
                      "type": "string",
                      "required": false,
                      "description": "The MIME type of the document contained in the wrapper object.",
                      "nested_params": []
                    },
                    {
                      "name": "data",
                      "type": "bytes",
                      "required": false,
                      "description": "The byte value of the file to upload, encoded as a Base-64 string.",
                      "nested_params": []
                    },
                    {
                      "name": "identifier",
                      "type": "string",
                      "required": false,
                      "description": "The file name of the document contained in the wrapper object.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "s3Location",
                  "type": "dict",
                  "required": false,
                  "description": "The S3 location of the external source wrapper object.",
                  "nested_params": [
                    {
                      "name": "uri",
                      "type": "string",
                      "required": false,
                      "description": "The file location of the S3 wrapper object.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "sourceType",
                  "type": "string",
                  "required": false,
                  "description": "The source type of the external source wrapper object.",
                  "nested_params": []
                }
              ]
            }
          ]
        },
        {
          "name": "knowledgeBaseConfiguration",
          "type": "dict",
          "required": false,
          "description": "Contains details about the knowledge base for retrieving information and generating responses.",
          "nested_params": [
            {
              "name": "generationConfiguration",
              "type": "dict",
              "required": false,
              "description": "Contains configurations for response generation based on the knowledge base query results.",
              "nested_params": [
                {
                  "name": "additionalModelRequestFields",
                  "type": "dict",
                  "required": false,
                  "description": "Additional model parameters and corresponding values not included in the textInferenceConfig structure for a knowledge base. This allows users to provide custom model parameters specific to the language model being used.",
                  "nested_params": []
                },
                {
                  "name": "guardrailConfiguration",
                  "type": "dict",
                  "required": false,
                  "description": "The configuration details for the guardrail.",
                  "nested_params": [
                    {
                      "name": "guardrailId",
                      "type": "string",
                      "required": false,
                      "description": "The unique identifier for the guardrail.",
                      "nested_params": []
                    },
                    {
                      "name": "guardrailVersion",
                      "type": "string",
                      "required": false,
                      "description": "The version of the guardrail.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "inferenceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "Configuration settings for inference when using RetrieveAndGenerate to generate responses while using a knowledge base as a source.",
                  "nested_params": [
                    {
                      "name": "textInferenceConfig",
                      "type": "dict",
                      "required": false,
                      "description": "Configuration settings specific to text generation while generating responses using RetrieveAndGenerate.",
                      "nested_params": [
                        {
                          "name": "maxTokens",
                          "type": "integer",
                          "required": false,
                          "description": "The maximum number of tokens to generate in the output text. Do not use the minimum of 0 or the maximum of 65536. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "stopSequences",
                          "type": "list",
                          "required": false,
                          "description": "A list of sequences of characters that, if generated, will cause the model to stop generating further tokens. Do not use a minimum length of 1 or a maximum length of 1000. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "temperature",
                          "type": "float",
                          "required": false,
                          "description": "Controls the random-ness of text generated by the language model, influencing how much the model sticks to the most predictable next words versus exploring more surprising options. A lower temperature value (e.g. 0.2 or 0.3) makes model outputs more deterministic or predictable, while a higher temperature (e.g. 0.8 or 0.9) makes the outputs more creative or unpredictable.",
                          "nested_params": []
                        },
                        {
                          "name": "topP",
                          "type": "float",
                          "required": false,
                          "description": "A probability distribution threshold which controls what the model considers for the set of possible next tokens. The model will only consider the top p% of the probability distribution when generating the next token.",
                          "nested_params": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "name": "performanceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "The latency configuration for the model.",
                  "nested_params": [
                    {
                      "name": "latency",
                      "type": "string",
                      "required": false,
                      "description": "To use a latency-optimized version of the model, set to optimized.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "promptTemplate",
                  "type": "dict",
                  "required": false,
                  "description": "Contains the template for the prompt that's sent to the model for response generation. Generation prompts must include the $search_results$ variable. For more information, see Use placeholder variables in the user guide.",
                  "nested_params": [
                    {
                      "name": "textPromptTemplate",
                      "type": "string",
                      "required": false,
                      "description": "The template for the prompt that's sent to the model for response generation. You can include prompt placeholders, which become replaced before the prompt is sent to the model to provide instructions and context to the model. In addition, you can include XML tags to delineate meaningful sections of the prompt template. For more information, see the following resources:",
                      "nested_params": []
                    }
                  ]
                }
              ]
            },
            {
              "name": "knowledgeBaseId",
              "type": "string",
              "required": false,
              "description": "The unique identifier of the knowledge base that is queried.",
              "nested_params": []
            },
            {
              "name": "modelArn",
              "type": "string",
              "required": false,
              "description": "The ARN of the foundation model or inference profile used to generate a response.",
              "nested_params": []
            },
            {
              "name": "orchestrationConfiguration",
              "type": "dict",
              "required": false,
              "description": "Settings for how the model processes the prompt prior to retrieval and generation.",
              "nested_params": [
                {
                  "name": "additionalModelRequestFields",
                  "type": "dict",
                  "required": false,
                  "description": "Additional model parameters and corresponding values not included in the textInferenceConfig structure for a knowledge base. This allows users to provide custom model parameters specific to the language model being used.",
                  "nested_params": []
                },
                {
                  "name": "inferenceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "Configuration settings for inference when using RetrieveAndGenerate to generate responses while using a knowledge base as a source.",
                  "nested_params": [
                    {
                      "name": "textInferenceConfig",
                      "type": "dict",
                      "required": false,
                      "description": "Configuration settings specific to text generation while generating responses using RetrieveAndGenerate.",
                      "nested_params": [
                        {
                          "name": "maxTokens",
                          "type": "integer",
                          "required": false,
                          "description": "The maximum number of tokens to generate in the output text. Do not use the minimum of 0 or the maximum of 65536. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "stopSequences",
                          "type": "list",
                          "required": false,
                          "description": "A list of sequences of characters that, if generated, will cause the model to stop generating further tokens. Do not use a minimum length of 1 or a maximum length of 1000. The limit values described here are arbitary values, for actual values consult the limits defined by your specific model.",
                          "nested_params": []
                        },
                        {
                          "name": "temperature",
                          "type": "float",
                          "required": false,
                          "description": "Controls the random-ness of text generated by the language model, influencing how much the model sticks to the most predictable next words versus exploring more surprising options. A lower temperature value (e.g. 0.2 or 0.3) makes model outputs more deterministic or predictable, while a higher temperature (e.g. 0.8 or 0.9) makes the outputs more creative or unpredictable.",
                          "nested_params": []
                        },
                        {
                          "name": "topP",
                          "type": "float",
                          "required": false,
                          "description": "A probability distribution threshold which controls what the model considers for the set of possible next tokens. The model will only consider the top p% of the probability distribution when generating the next token.",
                          "nested_params": []
                        }
                      ]
                    }
                  ]
                },
                {
                  "name": "performanceConfig",
                  "type": "dict",
                  "required": false,
                  "description": "The latency configuration for the model.",
                  "nested_params": [
                    {
                      "name": "latency",
                      "type": "string",
                      "required": false,
                      "description": "To use a latency-optimized version of the model, set to optimized.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "promptTemplate",
                  "type": "dict",
                  "required": false,
                  "description": "Contains the template for the prompt that's sent to the model. Orchestration prompts must include the $conversation_history$ and $output_format_instructions$ variables. For more information, see Use placeholder variables in the user guide.",
                  "nested_params": [
                    {
                      "name": "textPromptTemplate",
                      "type": "string",
                      "required": false,
                      "description": "The template for the prompt that's sent to the model for response generation. You can include prompt placeholders, which become replaced before the prompt is sent to the model to provide instructions and context to the model. In addition, you can include XML tags to delineate meaningful sections of the prompt template. For more information, see the following resources:",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "queryTransformationConfiguration",
                  "type": "dict",
                  "required": false,
                  "description": "To split up the prompt and retrieve multiple sources, set the transformation type to QUERY_DECOMPOSITION.",
                  "nested_params": [
                    {
                      "name": "type",
                      "type": "string",
                      "required": false,
                      "description": "The type of transformation to apply to the prompt.",
                      "nested_params": []
                    }
                  ]
                }
              ]
            },
            {
              "name": "retrievalConfiguration",
              "type": "dict",
              "required": false,
              "description": "Contains configurations for how to retrieve and return the knowledge base query.",
              "nested_params": [
                {
                  "name": "vectorSearchConfiguration",
                  "type": "dict",
                  "required": false,
                  "description": "Contains details about how the results from the vector search should be returned. For more information, see Query configurations.",
                  "nested_params": [
                    {
                      "name": "filter",
                      "type": "dict",
                      "required": false,
                      "description": "Specifies the filters to use on the metadata in the knowledge base data sources before returning results. For more information, see Query configurations.",
                      "nested_params": [
                        {
                          "name": "andAll",
                          "type": "list",
                          "required": false,
                          "description": "Knowledge base data sources are returned if their metadata attributes fulfill all the filter conditions inside this list.",
                          "nested_params": []
                        },
                        {
                          "name": "equals",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value matches the value in this object. The following example would return data sources with an animal attribute whose value is cat: \"equals\": { \"key\": \"animal\", \"value\": \"cat\" }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "greaterThan",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is greater than the value in this object. The following example would return data sources with an year attribute whose value is greater than 1989: \"greaterThan\": { \"key\": \"year\", \"value\": 1989 }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "greaterThanOrEquals",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is greater than or equal to the value in this object. The following example would return data sources with an year attribute whose value is greater than or equal to 1989: \"greaterThanOrEquals\": { \"key\": \"year\", \"value\": 1989 }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "in",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is in the list specified in the value in this object. The following example would return data sources with an animal attribute that is either cat or dog: \"in\": { \"key\": \"animal\", \"value\": [\"cat\", \"dog\"] }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "lessThan",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is less than the value in this object. The following example would return data sources with an year attribute whose value is less than to 1989. \"lessThan\": { \"key\": \"year\", \"value\": 1989 }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "lessThanOrEquals",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is less than or equal to the value in this object. The following example would return data sources with an year attribute whose value is less than or equal to 1989. \"lessThanOrEquals\": { \"key\": \"year\", \"value\": 1989 }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "listContains",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is a list that contains the value as one of its members. The following example would return data sources with an animals attribute that is a list containing a cat member (for example [\"dog\", \"cat\"]). \"listContains\": { \"key\": \"animals\", \"value\": \"cat\" }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "notEquals",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned when:",
                          "nested_params": []
                        },
                        {
                          "name": "notIn",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value isn't in the list specified in the value in this object. The following example would return data sources whose animal attribute is neither cat nor dog. \"notIn\": { \"key\": \"animal\", \"value\": [\"cat\", \"dog\"] }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "orAll",
                          "type": "list",
                          "required": false,
                          "description": "Knowledge base data sources are returned if their metadata attributes fulfill at least one of the filter conditions inside this list.",
                          "nested_params": []
                        },
                        {
                          "name": "startsWith",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value starts with the value in this object. This filter is currently only supported for Amazon OpenSearch Serverless vector stores. The following example would return data sources with an animal attribute starts with ca (for example, cat or camel). \"startsWith\": { \"key\": \"animal\", \"value\": \"ca\" }",
                          "nested_params": [
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The name that the metadata attribute must match.",
                              "nested_params": []
                            },
                            {
                              "name": "value",
                              "type": "document",
                              "required": true,
                              "description": "The value to whcih to compare the value of the metadata attribute.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "stringContains",
                          "type": "dict",
                          "required": false,
                          "description": "Knowledge base data sources are returned if they contain a metadata attribute whose name matches the key and whose value is one of the following:",
                          "nested_params": []
                        }
                      ]
                    },
                    {
                      "name": "implicitFilterConfiguration",
                      "type": "dict",
                      "required": false,
                      "description": "Settings for implicit filtering.",
                      "nested_params": [
                        {
                          "name": "metadataAttributes",
                          "type": "list",
                          "required": false,
                          "description": "Metadata that can be used in a filter.",
                          "nested_params": [
                            {
                              "name": "description",
                              "type": "string",
                              "required": false,
                              "description": "The attribute's description.",
                              "nested_params": []
                            },
                            {
                              "name": "key",
                              "type": "string",
                              "required": false,
                              "description": "The attribute's key.",
                              "nested_params": []
                            },
                            {
                              "name": "type",
                              "type": "string",
                              "required": false,
                              "description": "The attribute's type.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "modelArn",
                          "type": "string",
                          "required": false,
                          "description": "The model that generates the filter.",
                          "nested_params": []
                        }
                      ]
                    },
                    {
                      "name": "numberOfResults",
                      "type": "integer",
                      "required": false,
                      "description": "The number of source chunks to retrieve.",
                      "nested_params": []
                    },
                    {
                      "name": "overrideSearchType",
                      "type": "string",
                      "required": false,
                      "description": "By default, Amazon Bedrock decides a search strategy for you. If you're using an Amazon OpenSearch Serverless vector store that contains a filterable text field, you can specify whether to query the knowledge base with a HYBRID search using both vector embeddings and raw text, or SEMANTIC search using only vector embeddings. For other vector store configurations, only SEMANTIC search is available. For more information, see Test a knowledge base.",
                      "nested_params": []
                    },
                    {
                      "name": "rerankingConfiguration",
                      "type": "dict",
                      "required": false,
                      "description": "Contains configurations for reranking the retrieved results. For more information, see Improve the relevance of query responses with a reranker model.",
                      "nested_params": [
                        {
                          "name": "bedrockRerankingConfiguration",
                          "type": "dict",
                          "required": false,
                          "description": "Contains configurations for an Amazon Bedrock reranker model.",
                          "nested_params": [
                            {
                              "name": "metadataConfiguration",
                              "type": "dict",
                              "required": false,
                              "description": "Contains configurations for the metadata to use in reranking.",
                              "nested_params": [
                                {
                                  "name": "selectionMode",
                                  "type": "string",
                                  "required": false,
                                  "description": "Specifies whether to consider all metadata when reranking, or only the metadata that you select. If you specify SELECTIVE, include the selectiveModeConfiguration field.",
                                  "nested_params": []
                                },
                                {
                                  "name": "selectiveModeConfiguration",
                                  "type": "dict",
                                  "required": false,
                                  "description": "Contains configurations for the metadata fields to include or exclude when considering reranking.",
                                  "nested_params": [
                                    {
                                      "name": "fieldsToExclude",
                                      "type": "list",
                                      "required": false,
                                      "description": "An array of objects, each of which specifies a metadata field to exclude from consideration when reranking.",
                                      "nested_params": [
                                        {
                                          "name": "fieldName",
                                          "type": "string",
                                          "required": false,
                                          "description": "The name of a metadata field to include in or exclude from consideration when reranking.",
                                          "nested_params": []
                                        }
                                      ]
                                    },
                                    {
                                      "name": "fieldsToInclude",
                                      "type": "list",
                                      "required": false,
                                      "description": "An array of objects, each of which specifies a metadata field to include in consideration when reranking. The remaining metadata fields are ignored.",
                                      "nested_params": [
                                        {
                                          "name": "fieldName",
                                          "type": "string",
                                          "required": false,
                                          "description": "The name of a metadata field to include in or exclude from consideration when reranking.",
                                          "nested_params": []
                                        }
                                      ]
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "name": "modelConfiguration",
                              "type": "dict",
                              "required": false,
                              "description": "Contains configurations for the reranker model.",
                              "nested_params": [
                                {
                                  "name": "additionalModelRequestFields",
                                  "type": "dict",
                                  "required": false,
                                  "description": "A JSON object whose keys are request fields for the model and whose values are values for those fields.",
                                  "nested_params": []
                                },
                                {
                                  "name": "modelArn",
                                  "type": "string",
                                  "required": false,
                                  "description": "The ARN of the reranker model to use.",
                                  "nested_params": []
                                }
                              ]
                            },
                            {
                              "name": "numberOfRerankedResults",
                              "type": "integer",
                              "required": false,
                              "description": "The number of results to return after reranking.",
                              "nested_params": []
                            }
                          ]
                        },
                        {
                          "name": "type",
                          "type": "string",
                          "required": false,
                          "description": "The type of reranker model.",
                          "nested_params": []
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "name": "type",
          "type": "string",
          "required": false,
          "description": "The type of resource that contains your data for retrieving information and generating responses.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "sessionConfiguration",
      "type": "dict",
      "required": true,
      "description": "Contains details about the session with the knowledge base. The ARN of the KMS key encrypting the session.",
      "nested_params": [
        {
          "name": "kmsKeyArn",
          "type": "string",
          "required": false,
          "description": "The ARN of the KMS key encrypting the session.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "sessionId",
      "type": "string",
      "required": false,
      "description": "",
      "nested_params": []
    }
  ],
  "return_structure": [
    {
      "name": "",
      "type": "dict",
      "description": "",
      "nested_items": [
        {
          "name": "citations",
          "type": "list",
          "description": "A list of segments of the generated response that are based on sources in the knowledge base, alongside information about the sources.",
          "nested_items": [
            {
              "name": "",
              "type": "dict",
              "description": "",
              "nested_items": [
                {
                  "name": "",
                  "type": "",
                  "description": "InvokeAgent response --- in the citations field.",
                  "nested_items": []
                },
                {
                  "name": "",
                  "type": "",
                  "description": "RetrieveAndGenerate response --- in the citations field.",
                  "nested_items": []
                }
              ]
            }
          ]
        },
        {
          "name": "guardrailAction",
          "type": "string",
          "description": "Specifies if there is a guardrail intervention in the response.",
          "nested_items": []
        },
        {
          "name": "",
          "type": "dict",
          "description": "",
          "nested_items": [
            {
              "name": "text",
              "type": "string",
              "description": "The response generated from querying the knowledge base.",
              "nested_items": []
            }
          ]
        },
        {
          "name": "sessionId",
          "type": "string",
          "description": "The unique identifier of the session. When you first make a RetrieveAndGenerate request, Amazon Bedrock automatically generates this value. You must reuse this value for all subsequent requests in the same conversational session. This value allows Amazon Bedrock to maintain context and knowledge from previous interactions. You can't explicitly set the sessionId yourself.",
          "nested_items": []
        }
      ]
    }
  ]
}