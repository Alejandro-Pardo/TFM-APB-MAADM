{
  "method_name": "create_dataset_import_job",
  "url": "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/personalize/client/create_dataset_import_job.html",
  "description": "Creates a job that imports training data from your data source (an Amazon S3 bucket) to an Amazon Personalize dataset. To allow Amazon Personalize to import the training data, you must specify an IAM service role that has permission to read from the data source, as Amazon Personalize makes a copy of your data and processes it internally. For information on granting access to your Amazon S3 bucket, see Giving Amazon Personalize Access to Amazon S3 Resources. If you already created a recommender or deployed a custom solution version with a campaign, how new bulk records influence recommendations depends on the domain use case or recipe that you use. For more information, see How new data influences real-time recommendations. A dataset import job can be in one of the following states: To get the status of the import job, call DescribeDatasetImportJob, providing the Amazon Resource Name (ARN) of the dataset import job. The dataset import is complete when the status shows as ACTIVE. If the status shows as CREATE FAILED, the response includes a failureReason key, which describes why the job failed.",
  "parameters": [
    {
      "name": "jobName",
      "type": "string",
      "required": true,
      "description": "The name for the dataset import job.",
      "nested_params": []
    },
    {
      "name": "datasetArn",
      "type": "string",
      "required": true,
      "description": "The ARN of the dataset that receives the imported data.",
      "nested_params": []
    },
    {
      "name": "dataSource",
      "type": "dict",
      "required": true,
      "description": "The Amazon S3 bucket that contains the training data to import. dataLocation (string) --- For dataset import jobs, the path to the Amazon S3 bucket where the data that you want to upload to your dataset is stored. For data deletion jobs, the path to the Amazon S3 bucket that stores the list of records to delete. For example: s3://bucket-name/folder-name/fileName.csv If your CSV files are in a folder in your Amazon S3 bucket and you want your import job or data deletion job to consider multiple files, you can specify the path to the folder. With a data deletion job, Amazon Personalize uses all files in the folder and any sub folder. Use the following syntax with a / after the folder name: s3://bucket-name/folder-name/",
      "nested_params": [
        {
          "name": "dataLocation",
          "type": "string",
          "required": false,
          "description": "For dataset import jobs, the path to the Amazon S3 bucket where the data that you want to upload to your dataset is stored. For data deletion jobs, the path to the Amazon S3 bucket that stores the list of records to delete. For example: s3://bucket-name/folder-name/fileName.csv If your CSV files are in a folder in your Amazon S3 bucket and you want your import job or data deletion job to consider multiple files, you can specify the path to the folder. With a data deletion job, Amazon Personalize uses all files in the folder and any sub folder. Use the following syntax with a / after the folder name: s3://bucket-name/folder-name/",
          "nested_params": []
        }
      ]
    },
    {
      "name": "roleArn",
      "type": "string",
      "required": true,
      "description": "The ARN of the IAM role that has permissions to read from the Amazon S3 data source.",
      "nested_params": []
    },
    {
      "name": "tags",
      "type": "list",
      "required": true,
      "description": "A list of tags to apply to the dataset import job. (dict) --- The optional metadata that you apply to resources to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. For more information see Tagging Amazon Personalize resources. One part of a key-value pair that makes up a tag. A key is a general label that acts like a category for more specific tag values. The optional part of a key-value pair that makes up a tag. A value acts as a descriptor within a tag category (key).",
      "nested_params": [
        {
          "name": "tagKey",
          "type": "string",
          "required": false,
          "description": "One part of a key-value pair that makes up a tag. A key is a general label that acts like a category for more specific tag values.",
          "nested_params": []
        },
        {
          "name": "tagValue",
          "type": "string",
          "required": false,
          "description": "The optional part of a key-value pair that makes up a tag. A value acts as a descriptor within a tag category (key).",
          "nested_params": []
        }
      ]
    },
    {
      "name": "importMode",
      "type": "string",
      "required": false,
      "description": "Specify how to add the new records to an existing dataset. The default import mode is FULL. If you haven't imported bulk records into the dataset previously, you can only specify FULL. Specify FULL to overwrite all existing bulk data in your dataset. Data you imported individually is not replaced. Specify INCREMENTAL to append the new records to the existing data in your dataset. Amazon Personalize replaces any record with the same ID with the new one.",
      "nested_params": []
    },
    {
      "name": "publishAttributionMetricsToS3",
      "type": "boolean",
      "required": false,
      "description": "",
      "nested_params": []
    }
  ],
  "return_structure": [
    {
      "name": "",
      "type": "dict",
      "description": "",
      "nested_items": [
        {
          "name": "datasetImportJobArn",
          "type": "string",
          "description": "The ARN of the dataset import job.",
          "nested_items": []
        }
      ]
    }
  ]
}