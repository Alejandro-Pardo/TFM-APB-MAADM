{
  "method_name": "create_model_explainability_job_definition",
  "url": "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model_explainability_job_definition.html",
  "description": "Creates the definition for a model explainability job.",
  "parameters": [
    {
      "name": "JobDefinitionName",
      "type": "string",
      "required": true,
      "description": "The name of the model explainability job definition. The name must be unique within an Amazon Web Services Region in the Amazon Web Services account.",
      "nested_params": []
    },
    {
      "name": "ModelExplainabilityBaselineConfig",
      "type": "dict",
      "required": false,
      "description": "The baseline configuration for a model explainability job. BaseliningJobName (string) --- The name of the baseline model explainability job. ConstraintsResource (dict) --- The constraints resource for a monitoring job. S3Uri (string) --- The Amazon S3 URI for the constraints resource.",
      "nested_params": [
        {
          "name": "BaseliningJobName",
          "type": "string",
          "required": false,
          "description": "The name of the baseline model explainability job.",
          "nested_params": []
        },
        {
          "name": "ConstraintsResource",
          "type": "dict",
          "required": false,
          "description": "The constraints resource for a monitoring job.",
          "nested_params": [
            {
              "name": "S3Uri",
              "type": "string",
              "required": false,
              "description": "The Amazon S3 URI for the constraints resource.",
              "nested_params": []
            }
          ]
        }
      ]
    },
    {
      "name": "ModelExplainabilityAppSpecification",
      "type": "dict",
      "required": true,
      "description": "Configures the model explainability job to run a specified Docker container image. The container image to be run by the model explainability job. JSON formatted Amazon S3 file that defines explainability parameters. For more information on this JSON configuration file, see Configure model explainability parameters. Environment (dict) --- Sets the environment variables in the Docker container. (string) --- (string) ---",
      "nested_params": [
        {
          "name": "ImageUri",
          "type": "string",
          "required": false,
          "description": "The container image to be run by the model explainability job.",
          "nested_params": []
        },
        {
          "name": "ConfigUri",
          "type": "string",
          "required": false,
          "description": "JSON formatted Amazon S3 file that defines explainability parameters. For more information on this JSON configuration file, see Configure model explainability parameters.",
          "nested_params": []
        },
        {
          "name": "Environment",
          "type": "dict",
          "required": false,
          "description": "Sets the environment variables in the Docker container.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "ModelExplainabilityJobInput",
      "type": "dict",
      "required": true,
      "description": "Inputs for the model explainability job. EndpointInput (dict) --- Input object for the endpoint An endpoint in customer's account which has enabled DataCaptureConfig enabled. Path to the filesystem where the endpoint data is available to the container. S3InputMode (string) --- Whether the Pipe or File is used as the input mode for transferring data for the monitoring job. Pipe mode is recommended for large datasets. File mode is useful for small files that fit in memory. Defaults to File. S3DataDistributionType (string) --- Whether input data distributed in Amazon S3 is fully replicated or sharded by an Amazon S3 key. Defaults to FullyReplicated FeaturesAttribute (string) --- The attributes of the input data that are the input features. InferenceAttribute (string) --- The attribute of the input data that represents the ground truth label. ProbabilityAttribute (string) --- In a classification problem, the attribute that represents the class probability. ProbabilityThresholdAttribute (float) --- The threshold for the class probability to be evaluated as a positive result. StartTimeOffset (string) --- If specified, monitoring jobs substract this time from the start time. For information about using offsets for scheduling monitoring jobs, see Schedule Model Quality Monitoring Jobs. EndTimeOffset (string) --- If specified, monitoring jobs substract this time from the end time. ExcludeFeaturesAttribute (string) --- The attributes of the input data to exclude from the analysis. BatchTransformInput (dict) --- Input object for the batch transform job. The Amazon S3 location being used to capture the data. The dataset format for your batch transform job. Csv (dict) --- The CSV dataset used in the monitoring job. Header (boolean) --- Indicates if the CSV data has a header. Json (dict) --- The JSON dataset used in the monitoring job Line (boolean) --- Indicates if the file should be read as a JSON object per line. Parquet (dict) --- The Parquet dataset used in the monitoring job Path to the filesystem where the batch transform data is available to the container. S3DataDistributionType (string) --- Whether input data distributed in Amazon S3 is fully replicated or sharded by an S3 key. EndTimeOffset (string) --- If specified, monitoring jobs subtract this time from the end time. ExcludeFeaturesAttribute (string) --- The attributes of the input data to exclude from the analysis.",
      "nested_params": [
        {
          "name": "EndpointInput",
          "type": "dict",
          "required": false,
          "description": "Input object for the endpoint.",
          "nested_params": [
            {
              "name": "EndpointName",
              "type": "string",
              "required": false,
              "description": "An endpoint in customer's account which has enabled DataCaptureConfig enabled.",
              "nested_params": []
            },
            {
              "name": "LocalPath",
              "type": "string",
              "required": false,
              "description": "Path to the filesystem where the endpoint data is available to the container.",
              "nested_params": []
            },
            {
              "name": "S3InputMode",
              "type": "string",
              "required": false,
              "description": "Whether the Pipe or File is used as the input mode for transferring data for the monitoring job. Pipe mode is recommended for large datasets. File mode is useful for small files that fit in memory. Defaults to File.",
              "nested_params": []
            },
            {
              "name": "S3DataDistributionType",
              "type": "string",
              "required": false,
              "description": "Whether input data distributed in Amazon S3 is fully replicated or sharded by an Amazon S3 key. Defaults to FullyReplicated.",
              "nested_params": []
            },
            {
              "name": "FeaturesAttribute",
              "type": "string",
              "required": false,
              "description": "The attributes of the input data that are the input features.",
              "nested_params": []
            },
            {
              "name": "InferenceAttribute",
              "type": "string",
              "required": false,
              "description": "The attribute of the input data that represents the ground truth label.",
              "nested_params": []
            },
            {
              "name": "ProbabilityAttribute",
              "type": "string",
              "required": false,
              "description": "In a classification problem, the attribute that represents the class probability.",
              "nested_params": []
            },
            {
              "name": "ProbabilityThresholdAttribute",
              "type": "float",
              "required": false,
              "description": "The threshold for the class probability to be evaluated as a positive result.",
              "nested_params": []
            },
            {
              "name": "StartTimeOffset",
              "type": "string",
              "required": false,
              "description": "If specified, monitoring jobs substract this time from the start time. For information about using offsets for scheduling monitoring jobs, see Schedule Model Quality Monitoring Jobs.",
              "nested_params": []
            },
            {
              "name": "EndTimeOffset",
              "type": "string",
              "required": false,
              "description": "If specified, monitoring jobs substract this time from the end time. For information about using offsets for scheduling monitoring jobs, see Schedule Model Quality Monitoring Jobs.",
              "nested_params": []
            },
            {
              "name": "ExcludeFeaturesAttribute",
              "type": "string",
              "required": false,
              "description": "The attributes of the input data to exclude from the analysis.",
              "nested_params": []
            }
          ]
        },
        {
          "name": "BatchTransformInput",
          "type": "dict",
          "required": false,
          "description": "Input object for the batch transform job.",
          "nested_params": [
            {
              "name": "DataCapturedDestinationS3Uri",
              "type": "string",
              "required": false,
              "description": "The Amazon S3 location being used to capture the data.",
              "nested_params": []
            },
            {
              "name": "DatasetFormat",
              "type": "dict",
              "required": false,
              "description": "The dataset format for your batch transform job.",
              "nested_params": [
                {
                  "name": "Csv",
                  "type": "dict",
                  "required": false,
                  "description": "The CSV dataset used in the monitoring job.",
                  "nested_params": [
                    {
                      "name": "Header",
                      "type": "boolean",
                      "required": false,
                      "description": "Indicates if the CSV data has a header.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "Json",
                  "type": "dict",
                  "required": false,
                  "description": "The JSON dataset used in the monitoring job.",
                  "nested_params": [
                    {
                      "name": "Line",
                      "type": "boolean",
                      "required": false,
                      "description": "Indicates if the file should be read as a JSON object per line.",
                      "nested_params": []
                    }
                  ]
                },
                {
                  "name": "Parquet",
                  "type": "dict",
                  "required": false,
                  "description": "The Parquet dataset used in the monitoring job.",
                  "nested_params": []
                }
              ]
            },
            {
              "name": "LocalPath",
              "type": "string",
              "required": false,
              "description": "Path to the filesystem where the batch transform data is available to the container.",
              "nested_params": []
            },
            {
              "name": "S3InputMode",
              "type": "string",
              "required": false,
              "description": "Whether the Pipe or File is used as the input mode for transferring data for the monitoring job. Pipe mode is recommended for large datasets. File mode is useful for small files that fit in memory. Defaults to File.",
              "nested_params": []
            },
            {
              "name": "S3DataDistributionType",
              "type": "string",
              "required": false,
              "description": "Whether input data distributed in Amazon S3 is fully replicated or sharded by an S3 key. Defaults to FullyReplicated.",
              "nested_params": []
            },
            {
              "name": "FeaturesAttribute",
              "type": "string",
              "required": false,
              "description": "The attributes of the input data that are the input features.",
              "nested_params": []
            },
            {
              "name": "InferenceAttribute",
              "type": "string",
              "required": false,
              "description": "The attribute of the input data that represents the ground truth label.",
              "nested_params": []
            },
            {
              "name": "ProbabilityAttribute",
              "type": "string",
              "required": false,
              "description": "In a classification problem, the attribute that represents the class probability.",
              "nested_params": []
            },
            {
              "name": "ProbabilityThresholdAttribute",
              "type": "float",
              "required": false,
              "description": "The threshold for the class probability to be evaluated as a positive result.",
              "nested_params": []
            },
            {
              "name": "StartTimeOffset",
              "type": "string",
              "required": false,
              "description": "If specified, monitoring jobs substract this time from the start time. For information about using offsets for scheduling monitoring jobs, see Schedule Model Quality Monitoring Jobs.",
              "nested_params": []
            },
            {
              "name": "EndTimeOffset",
              "type": "string",
              "required": false,
              "description": "If specified, monitoring jobs subtract this time from the end time. For information about using offsets for scheduling monitoring jobs, see Schedule Model Quality Monitoring Jobs.",
              "nested_params": []
            },
            {
              "name": "ExcludeFeaturesAttribute",
              "type": "string",
              "required": false,
              "description": "The attributes of the input data to exclude from the analysis.",
              "nested_params": []
            }
          ]
        }
      ]
    },
    {
      "name": "ModelExplainabilityJobOutputConfig",
      "type": "dict",
      "required": true,
      "description": "The output configuration for monitoring jobs. Monitoring outputs for monitoring jobs. This is where the output of the periodic monitoring jobs is uploaded. (dict) --- The output object for a monitoring job. The Amazon S3 storage location where the results of a monitoring job are saved. A URI that identifies the Amazon S3 storage location where Amazon SageMaker AI saves the results of a monitoring job. The local path to the Amazon S3 storage location where Amazon SageMaker AI saves the results of a monitoring job. LocalPath is an absolute path for the output data. S3UploadMode (string) --- Whether to upload the results of the monitoring job continuously or after the job completes. KmsKeyId (string) --- The Key Management Service (KMS) key that Amazon SageMaker AI uses to encrypt the model artifacts at rest using Amazon S3 server-side encryption.",
      "nested_params": [
        {
          "name": "MonitoringOutputs",
          "type": "list",
          "required": false,
          "description": "Monitoring outputs for monitoring jobs. This is where the output of the periodic monitoring jobs is uploaded.",
          "nested_params": [
            {
              "name": "S3Output",
              "type": "dict",
              "required": false,
              "description": "The Amazon S3 storage location where the results of a monitoring job are saved.",
              "nested_params": [
                {
                  "name": "S3Uri",
                  "type": "string",
                  "required": false,
                  "description": "A URI that identifies the Amazon S3 storage location where Amazon SageMaker AI saves the results of a monitoring job.",
                  "nested_params": []
                },
                {
                  "name": "LocalPath",
                  "type": "string",
                  "required": false,
                  "description": "The local path to the Amazon S3 storage location where Amazon SageMaker AI saves the results of a monitoring job. LocalPath is an absolute path for the output data.",
                  "nested_params": []
                },
                {
                  "name": "S3UploadMode",
                  "type": "string",
                  "required": false,
                  "description": "Whether to upload the results of the monitoring job continuously or after the job completes.",
                  "nested_params": []
                }
              ]
            }
          ]
        },
        {
          "name": "KmsKeyId",
          "type": "string",
          "required": false,
          "description": "The Key Management Service (KMS) key that Amazon SageMaker AI uses to encrypt the model artifacts at rest using Amazon S3 server-side encryption.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "JobResources",
      "type": "dict",
      "required": true,
      "description": "Identifies the resources to deploy for a monitoring job. The configuration for the cluster resources used to run the processing job. The number of ML compute instances to use in the model monitoring job. For distributed processing jobs, specify a value greater than 1. The default value is 1. The ML compute instance type for the processing job. The size of the ML storage volume, in gigabytes, that you want to provision. You must specify sufficient ML storage for your scenario. VolumeKmsKeyId (string) --- The Key Management Service (KMS) key that Amazon SageMaker AI uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the model monitoring job.",
      "nested_params": [
        {
          "name": "ClusterConfig",
          "type": "dict",
          "required": false,
          "description": "The configuration for the cluster resources used to run the processing job.",
          "nested_params": [
            {
              "name": "InstanceCount",
              "type": "integer",
              "required": false,
              "description": "The number of ML compute instances to use in the model monitoring job. For distributed processing jobs, specify a value greater than 1. The default value is 1.",
              "nested_params": []
            },
            {
              "name": "InstanceType",
              "type": "string",
              "required": false,
              "description": "The ML compute instance type for the processing job.",
              "nested_params": []
            },
            {
              "name": "VolumeSizeInGB",
              "type": "integer",
              "required": false,
              "description": "The size of the ML storage volume, in gigabytes, that you want to provision. You must specify sufficient ML storage for your scenario.",
              "nested_params": []
            },
            {
              "name": "VolumeKmsKeyId",
              "type": "string",
              "required": false,
              "description": "The Key Management Service (KMS) key that Amazon SageMaker AI uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the model monitoring job.",
              "nested_params": []
            }
          ]
        }
      ]
    },
    {
      "name": "NetworkConfig",
      "type": "dict",
      "required": true,
      "description": "Networking options for a model explainability job. EnableInterContainerTrafficEncryption (boolean) --- Whether to encrypt all communications between the instances used for the monitoring jobs. Choose True to encrypt communications. Encryption provides greater security for distributed jobs, but the processing might take longer. EnableNetworkIsolation (boolean) --- Whether to allow inbound and outbound network calls to and from the containers used for the monitoring job. VpcConfig (dict) --- Specifies an Amazon Virtual Private Cloud (VPC) that your SageMaker jobs, hosted models, and compute resources have access to. You can control access to and from your resources by configuring a VPC. For more information, see Give SageMaker Access to Resources in your Amazon VPC. The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC that is specified in the Subnets field. (string) --- The ID of the subnets in the VPC to which you want to connect your training job or model. For information about the availability of specific instance types, see Supported Instance Types and Availability Zones. (string) ---",
      "nested_params": [
        {
          "name": "EnableInterContainerTrafficEncryption",
          "type": "boolean",
          "required": false,
          "description": "Whether to encrypt all communications between the instances used for the monitoring jobs. Choose True to encrypt communications. Encryption provides greater security for distributed jobs, but the processing might take longer.",
          "nested_params": []
        },
        {
          "name": "EnableNetworkIsolation",
          "type": "boolean",
          "required": false,
          "description": "Whether to allow inbound and outbound network calls to and from the containers used for the monitoring job.",
          "nested_params": []
        },
        {
          "name": "VpcConfig",
          "type": "dict",
          "required": false,
          "description": "Specifies an Amazon Virtual Private Cloud (VPC) that your SageMaker jobs, hosted models, and compute resources have access to. You can control access to and from your resources by configuring a VPC. For more information, see Give SageMaker Access to Resources in your Amazon VPC.",
          "nested_params": [
            {
              "name": "SecurityGroupIds",
              "type": "list",
              "required": false,
              "description": "The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC that is specified in the Subnets field.",
              "nested_params": []
            },
            {
              "name": "Subnets",
              "type": "list",
              "required": false,
              "description": "The ID of the subnets in the VPC to which you want to connect your training job or model. For information about the availability of specific instance types, see Supported Instance Types and Availability Zones.",
              "nested_params": []
            }
          ]
        }
      ]
    },
    {
      "name": "RoleArn",
      "type": "string",
      "required": true,
      "description": "The Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker AI can assume to perform tasks on your behalf.",
      "nested_params": []
    },
    {
      "name": "StoppingCondition",
      "type": "dict",
      "required": true,
      "description": "A time limit for how long the monitoring job is allowed to run before stopping. The maximum runtime allowed in seconds.",
      "nested_params": [
        {
          "name": "MaxRuntimeInSeconds",
          "type": "integer",
          "required": false,
          "description": "The maximum runtime allowed in seconds.",
          "nested_params": []
        }
      ]
    },
    {
      "name": "Tags",
      "type": "list",
      "required": true,
      "description": "(Optional) An array of key-value pairs. For more information, see Using Cost Allocation Tags in the Amazon Web Services Billing and Cost Management User Guide. (dict) --- A tag object that consists of a key and an optional value, used to manage metadata for SageMaker Amazon Web Services resources. You can add tags to notebook instances, training jobs, hyperparameter tuning jobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations, and endpoints. For more information on adding tags to SageMaker resources, see AddTags. For more information on adding metadata to your Amazon Web Services resources with tagging, see Tagging Amazon Web Services resources. For advice on best practices for managing Amazon Web Services resources with tagging, see Tagging Best Practices: Implement an Effective Amazon Web Services Resource Tagging Strategy. The tag key. Tag keys must be unique per resource. The tag value.",
      "nested_params": [
        {
          "name": "Key",
          "type": "string",
          "required": false,
          "description": "The tag key. Tag keys must be unique per resource.",
          "nested_params": []
        },
        {
          "name": "Value",
          "type": "string",
          "required": false,
          "description": "The tag value.",
          "nested_params": []
        }
      ]
    }
  ],
  "return_structure": [
    {
      "name": "",
      "type": "dict",
      "description": "",
      "nested_items": [
        {
          "name": "JobDefinitionArn",
          "type": "string",
          "description": "The Amazon Resource Name (ARN) of the model explainability job.",
          "nested_items": []
        }
      ]
    }
  ]
}